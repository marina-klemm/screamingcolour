[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Colours of the Taylor Swift Universe",
    "section": "",
    "text": "Screaming Colour: A Swiftie Guide to Eras Tour Stats\nA short collection of visualization and Rstats exercises exploring Taylor Swift‚Äôs use of colour in her Eras tour outfits and her lyrics!\nThis whole analysis started with a Swiftie curiosity over the selection of surprise songs‚Äô dresses colors and if they reflected the mood being sang in said songs. This then raised the question of which possible meaning that colors might have in the Swiftverse. Where do we even start analyzing that?\nWhat followed was months of metadata being added to songs; identifying every single time Swift mentions color and what they mean (it turns out, 45% of her songs mention color!); decision over which package to use to tokenize song‚Äôs moods and rate them on a scale of most negative to most positive; which led to another question: would lore collected by a long-time fan be more meaningful to identify the song‚Äôs meaning over an automated dictionary-based approach?\nOne might say this Swiftie fell in a rabbit hole, or is walking down Clown-elia Street again, but with Eras Tour ending and no signal of Debut (TV) or Reputation (TV) being released, there was some considerable amount of time that could be dedicated to this silly and fun passion project. ü§ì\nRather than Rstats if you‚Äôd simply like to make a Taylor Swift playlist based on sentiment, colours and/or muses then have a play with our Screaming Colour Taylor Swift Playlist Generator!\n\n\n\nSome r/TaylorSwift reading if you‚Äôre keen\n\nRe-calling album names in Taylor Swift Discography\nSnakegate timeline\nWhat would Taylor discography be like if snakegate didn‚Äôt happen?",
    "crumbs": [
      "Screaming Colour: A Swiftie Guide to Eras Tour Stats"
    ]
  },
  {
    "objectID": "data.html#the-lore-dataset",
    "href": "data.html#the-lore-dataset",
    "title": "1¬† The data!",
    "section": "1.1 The Lore dataset",
    "text": "1.1 The Lore dataset\nThe album_info_metadata.xlsx file includes the fan lore: sentiment, message, keywords, muse, color meaning, notes, secret messages, color mentions and their meanings (between positive or negative). The sentiments were chosen from a list of feelings compiled by the Hoffman Institute Foundation (May/2015 review). Soon it was realized that a single sentiment was not enough to completely differentiate between songs and the message and keywords were also created to add more information to single out a song. For example, while Tim McGraw and Back to December both have the overall nostalgic feeling, the first carries a falling in love message, while the latter is about longing. Likewise, Tim McGraw keywords are romantic, first love, country music, while Back to December keywords are breakup, regretful, heartbreak.\n\nallSongsMetadata <- readxl::read_excel(\"raw_data/album_info_metadata.xlsx\")[,1:29]\nallSongsMetadata \n\n# A tibble: 240 √ó 29\n   album_name ep    album_release       track_number track_name artist featuring\n   <chr>      <lgl> <dttm>                     <dbl> <chr>      <chr>  <chr>    \n 1 Red        FALSE 2021-11-12 00:00:00            6 \"22\"       Taylo‚Ä¶ <NA>     \n 2 1989       FALSE 2023-10-27 00:00:00           17 \"\\\"Slut!\\‚Ä¶ Taylo‚Ä¶ <NA>     \n 3 reputation FALSE 2017-11-10 00:00:00            1 \"...Ready‚Ä¶ Taylo‚Ä¶ <NA>     \n 4 Taylor Sw‚Ä¶ FALSE 2006-10-24 00:00:00           14 \"A Perfec‚Ä¶ Taylo‚Ä¶ <NA>     \n 5 Taylor Sw‚Ä¶ FALSE 2006-10-24 00:00:00            4 \"A Place ‚Ä¶ Taylo‚Ä¶ <NA>     \n 6 Lover      FALSE 2019-08-23 00:00:00           15 \"Afterglo‚Ä¶ Taylo‚Ä¶ <NA>     \n 7 Red        FALSE 2021-11-12 00:00:00            5 \"All Too ‚Ä¶ Taylo‚Ä¶ <NA>     \n 8 Red        FALSE 2021-11-12 00:00:00           30 \"All Too ‚Ä¶ Taylo‚Ä¶ <NA>     \n 9 1989       FALSE 2023-10-27 00:00:00            5 \"All You ‚Ä¶ Taylo‚Ä¶ <NA>     \n10 Midnights  FALSE 2022-10-21 00:00:00            3 \"Anti-Her‚Ä¶ Taylo‚Ä¶ <NA>     \n# ‚Ñπ 230 more rows\n# ‚Ñπ 22 more variables: bonus_track <lgl>, promotional_release <dttm>,\n#   single_release <dttm>, track_release <dttm>, danceability <dbl>,\n#   energy <dbl>, key <dbl>, loudness <dbl>, mode <dbl>, speechiness <dbl>,\n#   acousticness <dbl>, instrumentalness <dbl>, liveness <dbl>, valence <dbl>,\n#   tempo <dbl>, time_signature <dbl>, duration_ms <dbl>, explicit <lgl>,\n#   key_name <chr>, mode_name <chr>, key_mode <chr>, lyrics <chr>"
  },
  {
    "objectID": "data.html#the-lore-dataset-with-neutral-feelings",
    "href": "data.html#the-lore-dataset-with-neutral-feelings",
    "title": "1¬† The data!",
    "section": "1.2 The Lore dataset with neutral feelings",
    "text": "1.2 The Lore dataset with neutral feelings\nAfter compiling the first lore database, we realized that the mention of colors had more nuanced meaning than just a dicotomial division between ‚Äúpositive‚Äù or ‚Äúnegative‚Äù. Take the lyrics: * Drowning in the Blue Nile, he sent me ‚ÄòDowntown Lights‚Äô * You cinephile in black and white, all those plot twists and dynamite * My old blue jeans * I stracth your head, you fall asleep, like a tattoed golden retriever\nTo us, the examples above show usage of color as a purely discriptive adjective classifying a noun; there is no positive or negative feeling added in the qualifier, which contrasts to these examples: * We‚Äôre so sad, we paint the town blue (negative) * The rest of the world was black and white but we were in screaming color (negative) * I searched autora borealis green (positive) * It‚Äôs like your eyes are liquor, it‚Äôs like your body is gold (positive)\nTherefore, the album_info_metadata_neutral.xlsx file is a slight improvement from the original lore with posivive and/or negative being replaced by neutral where it felt appropriated.\n\nallSongsMetadata &lt;- \"raw_data/album_info_metadata_neutral.xlsx\"\nallSongsMetadata &lt;- readxl::read_excel(allSongsMetadata, sheet = \"metadata\")\nsource(\"code/colour_palletts.r\")\nrawColorData &lt;- data.frame(\n    colour = trimws(unlist(strsplit(allSongsMetadata$colour_MK, \";\"))),\n    meaning = trimws(unlist(strsplit(allSongsMetadata$colour_meaningMK, \";\")))\n) %&gt;% filter(!is.na(colour) & !is.na(meaning))\n\ncolorSentimentScores &lt;- rawColorData %&gt;%\n    mutate(\n        meaning = trimws(meaning),  \n        score = case_when(\n            tolower(meaning) == \"positive\" ~ 1,\n            tolower(meaning) == \"neutral\" ~ 0,\n            tolower(meaning) == \"negative\" ~ -1,\n            TRUE ~ NA_real_\n        )\n    )\n\n## Calculate average sentiment for each individual color\nindividualColorSentiments &lt;- colorSentimentScores %&gt;%\n    group_by(colour) %&gt;%\n    summarise(\n        avgSentiment = mean(score, na.rm = TRUE),\n        mentionCount = n()\n    ) %&gt;%\n    ungroup()\n\nindividualColorSentiments$colourGroup &lt;- colorGroups[individualColorSentiments$colour]\nindividualColorSentiments$colourHexColour &lt;-sapply(individualColorSentiments$colour, \\(x) colorPaletteColours[[x]])\nindividualColorSentiments$colourGroupColour &lt;-sapply(individualColorSentiments$colourGroup, \\(x) colorPaletteGroups[[x]])\n\nindividualColorSentiments\n\n# A tibble: 69 √ó 6\n   colour                avgSentiment mentionCount colourGroup   colourHexColour\n   &lt;chr&gt;                        &lt;dbl&gt;        &lt;int&gt; &lt;chr&gt;         &lt;chr&gt;          \n 1 amber                        0                1 yellows       #FFBF00        \n 2 aquamarine                   1                1 blues         #7FFFD4        \n 3 aurora borealis green        1                2 greens        #78E08F        \n 4 black                        0                9 blacks        #000000        \n 5 black and white             -0.5              4 black and wh‚Ä¶ #C0C0C0        \n 6 blackout                     1                1 blacks        #1A1A1A        \n 7 bleached                     0                1 whites        #F5F5DC        \n 8 blood monlit                 1                1 reds          #8A0303        \n 9 blood-soaked                -1                2 reds          #8B0000        \n10 blue                        -0.182           22 blues         #0000FF        \n# ‚Ñπ 59 more rows\n# ‚Ñπ 1 more variable: colourGroupColour &lt;chr&gt;",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>The data!</span>"
    ]
  },
  {
    "objectID": "data.html#sec-surp",
    "href": "data.html#sec-surp",
    "title": "1¬† The data!",
    "section": "1.3 Surprise Songs Data Set",
    "text": "1.3 Surprise Songs Data Set\nParallel to the development of the metadata (aka lore) database, a few details about each surprise song performance were noted down in the surprise_songs.xlsx data set. Each concert had a few rows, one per surprise song (Taylor performed two surprise songs in each of the concerts, the first one on the guitar and the second one on the piano). Besides the two regular surprise songs, she occasionally started mashing up songs in this acoustic set; although the first mashup happened in her second night in Ohio (July 1st, 2023), they became more common from the second night of her Melbourne concert (February 17th, 2024). Thus, three columns account for it: Mashups, with the options none, one or two; Mashup, with the name of the first song mashed up with Song title; and, Mashup2, with yet a third song that was mashed up with Song title and Mashup (in the case of Mashups = Two).\nBesides the song titles and mashups, the surprise songs data set includes the names of the city, state, country, stadium and dates in which she performed. Moreover, the name of the dress she was wearing is included in the column DressName, and its color in descriptive terms is found on Colour1, its HEX formatting on ColourHex1, and its RGB formatting on ColourRGB1. As some dresses like Flamingo pink and Sunset orange are made up of an ombre of two colors, their name and codes are also found on Colour2, ColourHex2 and ColourRGB2. Lastly, other details are also included: who she was dating at the time in the Relationship column; which leg of the tour (First legs, European, Final leg), which night on that city, which instrument she played while singing said song, special guests in the audience, and notes for overall remarks such as: on July 9th, she sang Last Kiss as one the surprise songs, and that date is mentioned on the song.\n\n## reading in data\nsurpriseSongsDressColours &lt;-  readxl::read_excel(\"raw_data/surprise_songs.xlsx\", sheet = \"List\")\nsurpriseSongsDressColours$Date &lt;- as.Date(surpriseSongsDressColours$Date)\nsurpriseSongsDressColours\n\n# A tibble: 443 √ó 26\n   `Song title`         Mashups Mashup Mashup2 Guest City  State Country Stadium\n   &lt;chr&gt;                &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;  \n 1 mirrorball           None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Glen‚Ä¶ Ariz‚Ä¶ US      State ‚Ä¶\n 2 Tim McGraw           None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Glen‚Ä¶ Ariz‚Ä¶ US      State ‚Ä¶\n 3 State Of Grace       None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Glen‚Ä¶ Ariz‚Ä¶ US      State ‚Ä¶\n 4 this is me trying    None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Glen‚Ä¶ Ariz‚Ä¶ US      State ‚Ä¶\n 5 Our Song             None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Las ‚Ä¶ Neva‚Ä¶ US      Allegi‚Ä¶\n 6 Snow On The Beach    None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Las ‚Ä¶ Neva‚Ä¶ US      Allegi‚Ä¶\n 7 cowboy like me       None    &lt;NA&gt;   &lt;NA&gt;    Marc‚Ä¶ Las ‚Ä¶ Neva‚Ä¶ US      Allegi‚Ä¶\n 8 White Horse          None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Las ‚Ä¶ Neva‚Ä¶ US      Allegi‚Ä¶\n 9 Ours                 None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Arli‚Ä¶ Texas US      AT&T   \n10 Sad Beautiful Tragic None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Arli‚Ä¶ Texas US      AT&T   \n# ‚Ñπ 433 more rows\n# ‚Ñπ 17 more variables: Date &lt;date&gt;, DressName &lt;chr&gt;, Legs &lt;chr&gt;,\n#   Relationship &lt;chr&gt;, Start &lt;dttm&gt;, End &lt;dttm&gt;, Colour1 &lt;chr&gt;,\n#   ColourHex1 &lt;chr&gt;, ColourRGB1 &lt;chr&gt;, Colour2 &lt;chr&gt;, ColourHex2 &lt;chr&gt;,\n#   ColourRGB2 &lt;chr&gt;, `Night #` &lt;dbl&gt;, Order &lt;dbl&gt;, Instrument &lt;chr&gt;,\n#   `Special Annoucement` &lt;chr&gt;, Notes &lt;chr&gt;\n\n\n\n1.3.1 An overview of surprise song dresses across the whole tour\n\n## Need only consider first element of each concerts as the\n## same outfit was worn for all surprise songs\n## for anyone concert\noneRowPerConcert &lt;- surpriseSongsDressColours %&gt;%\n    group_by(Date) %&gt;%\n    arrange(Date, Order) %&gt;% \n    slice(1) %&gt;%\n    ungroup()\noneRowPerConcert\n\n# A tibble: 147 √ó 26\n   `Song title`         Mashups Mashup Mashup2 Guest City  State Country Stadium\n   &lt;chr&gt;                &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;  \n 1 mirrorball           None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Glen‚Ä¶ Ariz‚Ä¶ US      State ‚Ä¶\n 2 this is me trying    None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Glen‚Ä¶ Ariz‚Ä¶ US      State ‚Ä¶\n 3 Our Song             None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Las ‚Ä¶ Neva‚Ä¶ US      Allegi‚Ä¶\n 4 cowboy like me       None    &lt;NA&gt;   &lt;NA&gt;    Marc‚Ä¶ Las ‚Ä¶ Neva‚Ä¶ US      Allegi‚Ä¶\n 5 Sad Beautiful Tragic None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Arli‚Ä¶ Texas US      AT&T   \n 6 Death By A Thousand‚Ä¶ None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Arli‚Ä¶ Texas US      AT&T   \n 7 Speak Now            None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Tampa Flor‚Ä¶ US      Raymon‚Ä¶\n 8 The Great War        None    &lt;NA&gt;   &lt;NA&gt;    Aaro‚Ä¶ Tampa Flor‚Ä¶ US      Raymon‚Ä¶\n 9 mad woman            None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Tampa Flor‚Ä¶ US      Raymon‚Ä¶\n10 Wonderland           None    &lt;NA&gt;   &lt;NA&gt;    &lt;NA&gt;  Hous‚Ä¶ Texas US      NRG    \n# ‚Ñπ 137 more rows\n# ‚Ñπ 17 more variables: Date &lt;date&gt;, DressName &lt;chr&gt;, Legs &lt;chr&gt;,\n#   Relationship &lt;chr&gt;, Start &lt;dttm&gt;, End &lt;dttm&gt;, Colour1 &lt;chr&gt;,\n#   ColourHex1 &lt;chr&gt;, ColourRGB1 &lt;chr&gt;, Colour2 &lt;chr&gt;, ColourHex2 &lt;chr&gt;,\n#   ColourRGB2 &lt;chr&gt;, `Night #` &lt;dbl&gt;, Order &lt;dbl&gt;, Instrument &lt;chr&gt;,\n#   `Special Annoucement` &lt;chr&gt;, Notes &lt;chr&gt;",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>The data!</span>"
    ]
  },
  {
    "objectID": "viz.html#the-most-worn-looks",
    "href": "viz.html#the-most-worn-looks",
    "title": "2¬† Visualizing the data",
    "section": "The most worn looks",
    "text": "The most worn looks\n\n\nCode\n## map hex colour to outfit\ndressColorMapping <- unique(surpriseSongsDressColours %>% select(DressName, ColourHex1))\ncolorPaletteDresses <- setNames(dressColorMapping$ColourHex1, dressColorMapping$DressName)\npathToDressColours <- \"dress_images/images_high_res/cropped/\"\n## map outfits to the corresponding images\noneRowPerConcert %>%\n    count(DressName) %>%\n    mutate(\n        percentage = n / sum(n) * 100,\n        imagePath = case_when(\n            DressName == \"Pink\" ~paste0(pathToDressColours, \"pink.jpg\"),\n            DressName == \"Green\" ~paste0(pathToDressColours, \"green.jpg\"),\n            DressName == \"Yellow\" ~paste0(pathToDressColours, \"yellow.jpg\"),\n            DressName == \"Blue\" ~paste0(pathToDressColours, \"blue.jpg\"),\n            DressName == \"Flamingo pink\" ~ paste0(pathToDressColours,\"flamingo_pink.jpg\"),\n            DressName == \"Ocean blue\" ~ paste0(pathToDressColours,\"ocean_blue.jpg\"),\n            DressName == \"Sunset orange\" ~ paste0(pathToDressColours,\"sunset_orange.jpg\"),\n            DressName == \"Cotton candy\" ~paste0(pathToDressColours, \"cotton_candy.jpg\"),\n            DressName == \"Blurple\" ~paste0(pathToDressColours, \"blurple.jpg\"),\n            DressName == \"Grapefruit\" ~ paste0(pathToDressColours,\"grapefruit.jpg\"),\n            DressName == \"Popsicle\" ~ paste0(pathToDressColours,\"popsicle.jpg\"),\n            TRUE ~ NA_character_\n        )) -> outfits\n\n## barchart\nggplot(outfits, aes(x = reorder(DressName, -n), y = n, fill = DressName)) +\n    geom_bar(stat = \"identity\", width = 0.8) +  \n    geom_image(\n        aes(image = imagePath, y = n),  \n        size = 0.15,                    \n        by = \"height\"                    \n    ) +\n    geom_text(\n        aes(y = n + 3.8, label = paste0(n, \"\\n(\", round(percentage, 1), \"%)\")),  \n        vjust = 0,  \n        color = \"black\",\n        size = 4\n    ) +\n    scale_fill_manual(values = colorPaletteDresses) +\n    theme_minimal() +\n    labs(title = \"\", x = \"\", y = \"\") +\n    theme(\n        axis.text.x = element_text(angle = 45, hjust = 1, size = 14),\n        axis.text.y = element_text(size = 14),\n        plot.title = element_text(hjust = 0.5, size = 16),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        legend.position = \"none\"\n    ) + ylim(0, 35)"
  },
  {
    "objectID": "viz.html#eras-outfits-and-special-events",
    "href": "viz.html#eras-outfits-and-special-events",
    "title": "2¬† Visualizing the data",
    "section": "Eras‚Äô Outfits and Special Events",
    "text": "Eras‚Äô Outfits and Special Events\n\n\nCode\ndress_first_appearance &lt;- surpriseSongsDressColours %&gt;%\n  group_by(DressName) %&gt;%\n  summarize(FirstAppearance = min(Date)) %&gt;%\n  arrange((FirstAppearance))\nsurpriseSongsDressColours$DressName &lt;- factor(surpriseSongsDressColours$DressName,\n                                              levels = dress_first_appearance$DressName)\nmax_dress_level &lt;- length(unique(surpriseSongsDressColours$DressName))\ndress_levels &lt;- levels(factor(surpriseSongsDressColours$DressName))\noutfits$DressName &lt;- factor(outfits$DressName, levels = dress_levels)\n\nmain_plot &lt;- ggplot(surpriseSongsDressColours, aes(x = as.Date(Date), y = DressName, color = ColourHex1)) +\n    geom_point(size = 4, alpha = 1) +\n    scale_color_identity() +\n    theme_minimal() +\n    labs(title = \"\", x = \"\", y = \"\" ) +\n    geom_rect(aes(xmin = as.Date(\"2023-08-28\"), xmax = as.Date(\"2023-11-08\"),\n                  ymin = -Inf, ymax = Inf), fill = \"gray\", alpha = 0.01, color = NA) +\n    geom_rect(aes(xmin = as.Date(\"2023-11-27\"), xmax = as.Date(\"2024-02-06\"),\n                  ymin = -Inf, ymax = Inf), fill = \"gray\", alpha = 0.01, color = NA) +  \n    geom_rect(aes(xmin = as.Date(\"2024-03-10\"), xmax = as.Date(\"2024-05-08\"),\n                  ymin = -Inf, ymax = Inf), fill = \"gray\", alpha = 0.01, color = NA) +\n    geom_rect(aes(xmin = as.Date(\"2024-08-21\"), xmax = as.Date(\"2024-10-17\"),\n                  ymin = -Inf, ymax = Inf), fill = \"gray\", alpha = 0.01, color = NA) +\n    ## Vertical lines for the key events\n    geom_vline(xintercept = as.Date(\"2024-05-09\"), linetype = \"dashed\", color = \"black\") +\n    geom_vline(xintercept = as.Date(\"2023-03-17\"), linetype = \"dashed\", color = \"black\") +\n    geom_vline(xintercept = as.Date(\"2024-10-18\"), linetype = \"dashed\", color = \"black\") +\n    geom_vline(xintercept = as.Date(\"2023-08-24\"), linetype = \"dashed\", color = \"black\") +\n    geom_vline(xintercept = as.Date(\"2024-02-07\"), linetype = \"dashed\", color = \"black\") +\n    geom_vline(xintercept = as.Date(\"2024-04-16\"), linetype = \"solid\", color = \"darkgray\", linewidth = 2) +\n    ## Changed to 16 (the right day is 19th) for vis requirements\n    geom_vline(xintercept = as.Date(\"2023-07-07\"), linetype = \"solid\", color = \"purple\", linewidth = 2) +\n    geom_vline(xintercept = as.Date(\"2023-10-27\"), linetype = \"solid\", color = \"blue\", linewidth = 2) +\n    ## Text annotations for the events above\n    annotate(\"text\", x = as.Date(\"2024-05-09\"), y = max_dress_level, \n             label = \"Europe\\u00B9\", color = \"black\", angle = -90, vjust = -0.5,\n              size = 5) +\n    annotate(\"text\", x = as.Date(\"2023-03-17\"), y = max_dress_level, \n             label = \"United\\nStates\\u00B9\", color = \"black\", angle = -90, vjust = -0.2,\n              size = 5) +\n    annotate(\"text\", x = as.Date(\"2024-10-18\"), y = max_dress_level, \n             label = \"North \\nAmerica\\u00B9\", color = \"black\", angle = -90, vjust = -0.2,\n              size = 5) +\n    annotate(\"text\", x = as.Date(\"2023-08-24\"), y = max_dress_level, \n             label = \"Latin \\nAmerica\\u00B9\", color = \"black\", angle = -90, vjust = -0.2,\n              size = 5) +\n    annotate(\"text\", x = as.Date(\"2024-02-07\"), y = max_dress_level, \n             label = \"Asia/\\nOceania\\u00B9\", color = \"black\", angle = -90, vjust = -0.2,\n              size = 5) +\n    annotate(\"text\", x = as.Date(\"2024-04-16\"), y = max_dress_level, \n             label = \"TTPD\\u00B2\", color = \"darkgray\", angle = -90, vjust = -0.5,\n              size = 5) +\n    annotate(\"text\", x = as.Date(\"2023-07-07\"), y = max_dress_level, \n             label = \"Speak\\nNow TV\\u00B2\", color = \"purple\", angle = -90, vjust = -0.2,\n              size = 5) +\n    annotate(\"text\", x = as.Date(\"2023-10-27\"), y = max_dress_level, \n             label = \"1989\\nTV\\u00B2\", color = \"blue\", angle = -90, vjust = -0.2,\n             size = 5) +\n    scale_x_date(date_labels = \"%b %Y\", date_breaks = \"3 months\") +\n    theme(axis.text.x = element_text(angle = 0, hjust = 1, size = 14),\n          axis.text.y = element_text(size = 14, hjust = 0), \n          plot.title = element_text(hjust=0.5, size = 14, margin = margin(b = 20), face = \"bold\"),\n          plot.margin = margin(t = -7, r = 0, b = 10, l = 0),\n          text = element_text(color = \"black\", size = 14)) \n\ncount_plot &lt;- ggplot(outfits, aes(x = n, y = DressName, fill = DressName)) +\n    geom_bar(stat = \"identity\", width = 0.8) +\n    geom_image(\n        aes(image = imagePath, x = n),  \n        size = 0.09,                    \n        nudge_x = 2,\n        by = \"height\"                    \n    ) +\n    geom_text(\n        aes(x = n + 3, label = paste0(n, \" (\", round(percentage, 1), \"%)\")),  \n        hjust = 0,\n        nudge_x = 3,\n        color = \"black\",\n        size = 5\n    ) +\n    scale_fill_manual(values = colorPaletteDresses) +\n    theme_minimal() +\n    labs( title = \"\",x = \"\", y = \"\") +\n    theme(\n        axis.text.y = element_blank(),\n        axis.text.x = element_blank(),\n        plot.title = element_text(hjust = 0.5, size = 12),\n        legend.position = \"none\",\n        plot.margin = margin(t = -7, r = 0, b = 10, l = 0),\n        text = element_text(color = \"black\", size = 14)\n    ) + xlim(0, 50)\n\nmerged_plot &lt;- plot_grid(\n    count_plot, main_plot,\n    ncol = 2,\n    align = \"h\",\n    axis = \"tb\",\n    rel_widths = c(1.5, 3))\n\ntitle_with_subtitle &lt;- ggdraw() + \n    draw_label(\n        \"She Was Screaming Color\",\n        size = 20,\n        y = 0.55,\n        hjust = 0.5\n    ) +\n    draw_label(\n        \"Frequency and Timeline of Taylor Swift's Dress Colors Across Tour Legs\\u00B9 and Album Releases\\u00B2\",\n        size = 16,\n        y = 0.1,\n        hjust = 0.5)\n\nplot_grid(\n    title_with_subtitle, merged_plot,\n    ncol = 1,\n    rel_heights = c(0.2, 2))",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Visualizing the data</span>"
    ]
  },
  {
    "objectID": "viz.html#surprise-song-color-groups",
    "href": "viz.html#surprise-song-color-groups",
    "title": "2¬† Visualizing the data",
    "section": "Surprise song color groups",
    "text": "Surprise song color groups\n\n\nCode\nsurpriseSongsDressColours$groupName &lt;- sapply(surpriseSongsDressColours$DressName, function(color) {\n  if (color %in% c(\"Pink\", \"Flamingo pink\")) return(\"reds\")\n  if (color %in% c(\"Green\")) return(\"greens\")\n  if(color %in% c(\"Yellow\", \"Sunset orange\")) return(\"yellows\")\n  if (color %in% c(\"Ocean blue\", \"Blue\")) return (\"blues\")\n  if (color %in% c(\"Popsicle\", \"Cotton candy\", \"Grapefruit\")) return (\"colorful\")\n  if (color %in% c(\"Blurple\")) return(\"purples\")\n  return(\"Neutral\")\n})\n\nsongs_with_single_color_group &lt;- surpriseSongsDressColours %&gt;%\n  group_by(`Song title`) %&gt;%\n  summarize(\n    total_performances = n(),\n    unique_color_groups = n_distinct(groupName),\n    color_group = first(groupName) \n  ) %&gt;%\n  filter(unique_color_groups == 1, total_performances &gt; 1) %&gt;%\n  arrange(desc(total_performances))\n\nsingle_color_performances &lt;- surpriseSongsDressColours %&gt;%\n  filter(`Song title` %in% songs_with_single_color_group$`Song title`)\n\n## pics\nblues &lt;- paste(\"dress_drawings/\", c(\"blue\", \"Ocean blue\"), \".png\", sep = \"\")\nreds &lt;- paste(\"dress_drawings/\", c(\"pink\", \"Flamingo pink\"), \".png\", sep = \"\")\nyellows &lt;- paste(\"dress_drawings/\", c(\"yellow\", \"Sunset orange\"), \".png\", sep = \"\")\n\ncoords &lt;- circleProgressiveLayout(table(single_color_performances$groupName),\n                                  sizetype = 'area')\ncoords$id &lt;- names(table(single_color_performances$groupName))\n\ndf.gg &lt;- circleLayoutVertices(coords, npoints = 8, id = 4)\n\nsnames &lt;- single_color_performances %&gt;% select('Song title', groupName) %&gt;%\n  group_by(`Song title`) %&gt;% mutate(count = n()) %&gt;% ungroup() |&gt; unique()\n\nset.seed(1989) ## for jitter repel\n\nplot &lt;- ggplot() + theme_void() +\n  ## blues\n  geom_polygon(data = df.gg[df.gg$id == \"blues\",], aes(x = x, y = y),\n               fill = \"#0000FF\", alpha = 0.05) +\n  geom_text_repel(aes(x = coords$x[coords$id == \"blues\"], \n                      y = coords$y[coords$id == \"blues\"], \n                      label = snames$`Song title`[snames$groupName == \"blues\"]),\n                  col = \"navy\", \n                  nudge_y = -0.9, \n                  nudge_x = 0.05, \n                  segment.color = NA,\n                  size = 1.9*snames$count[snames$groupName == \"blues\"], \n                  box.padding = 0.05,\n                  max.overlaps = 30,\n                  force = 0.5,\n                  direction = \"y\") +\n  ## reds\n  geom_polygon(data = df.gg[df.gg$id == \"reds\",], aes(x = x, y = y),\n               fill = \"#FF0000\", alpha = 0.05)  +\n  geom_text_repel(aes(x = coords$x[coords$id == \"reds\"], \n                      y = coords$y[coords$id == \"reds\"], \n                      label = snames$`Song title`[snames$groupName == \"reds\"]),\n                  col = \"firebrick\", \n                  nudge_y = -0.7, \n                  nudge_x = 0.05, \n                  segment.color = NA,\n                  size = 1.9*snames$count[snames$groupName == \"reds\"], \n                  box.padding = 0.05,\n                  max.overlaps = 30,\n                  force = 0.5,\n                  direction = \"y\") +\n  ## yellows\n  geom_polygon(data = df.gg[df.gg$id == \"yellows\",], aes(x = x, y = y),\n               fill = \"#FFD700\", alpha = 0.05)  +\n  geom_text_repel(aes(x = coords$x[coords$id == \"yellows\"], \n                      y = coords$y[coords$id == \"yellows\"], \n                      label = snames$`Song title`[snames$groupName == \"yellows\"]),\n                  col = \"goldenrod\", \n                  nudge_y = 1.2, \n                  nudge_x = 0, \n                  segment.color = NA,\n                  size = 1.9*snames$count[snames$groupName == \"yellows\"], \n                  box.padding = 0.05,\n                  max.overlaps = 30,\n                  force = 0.5,\n                  direction = \"y\")\n\n# Improved dress scaling - slightly smaller to fit better\nget_dress_scale &lt;- function(dress_name) {\n  counts &lt;- c(\"Blue\" = 2, \"Ocean blue\" = 4, \"Pink\" = 8, \n              \"Flamingo pink\" = 7, \"Yellow\" = 7, \"Sunset orange\" = 11)\n  base_scale &lt;- 0.11\n  scale_factor &lt;- 0.012\n  return(base_scale + (counts[dress_name] * scale_factor))\n}\n\n# Final plot with adjusted dress positions\nggdraw() +\n  draw_plot(plot) +\n  draw_image(blues[1],  -0.23, 0.34, scale = get_dress_scale(\"Blue\")) +\n  draw_image(blues[2], -0.35, 0.25, scale = get_dress_scale(\"Ocean blue\")) +\n  draw_image(reds[1], 0, 0.19, scale = get_dress_scale(\"Pink\")) +\n  draw_image(reds[2], 0.32, 0.35, scale = get_dress_scale(\"Flamingo pink\")) +\n  draw_image(yellows[1], -0.28, -0.26, scale = get_dress_scale(\"Yellow\")) +\n  draw_image(yellows[2], -0.010, -0.33, scale = get_dress_scale(\"Sunset orange\"))",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Visualizing the data</span>"
    ]
  },
  {
    "objectID": "outfit_transitions.html#a-chi2-test-for-the-transition-counts",
    "href": "outfit_transitions.html#a-chi2-test-for-the-transition-counts",
    "title": "3¬† Are the surprise song outfits random?",
    "section": "3.1 A \\(\\chi^2\\)-test for the transition counts",
    "text": "3.1 A \\(\\chi^2\\)-test for the transition counts\nLikely, the first standard hypothesis test you think of for count/contingency data is the \\(\\chi^2\\)-test (or the chi-squared test). Essentially, this works by testing for equal transition rates (if the outfit choices were completely random we‚Äôd expect equal numbers of transitions between the outfits); Slightly more formally,\n\\(H_0 = \\text{row outfits independent of column outfits}\\) vs.¬†\\(H_1 = \\text{row outfits not independent of column outfits}\\).\n\n## first leg\nfirst_leg |> transitions() |> chisq.test()\n\n\n    Pearson's Chi-squared test\n\ndata:  transitions(first_leg)\nX-squared = 10.259, df = 9, p-value = 0.33\n\n## europe leg\nmid_leg |> transitions() |> chisq.test()\n\n\n    Pearson's Chi-squared test\n\ndata:  transitions(mid_leg)\nX-squared = 19.554, df = 4, p-value = 0.0006115\n\n## final leg\nfinal_leg |> transitions() |> chisq.test()\n\n\n    Pearson's Chi-squared test\n\ndata:  transitions(final_leg)\nX-squared = 17.337, df = 16, p-value = 0.3641\n\n\n\n\n\n\nTable¬†3.1: Summary of the chi-squared tests on the transition matricies for each leg of the Eras tour.\n\n\n\nChi-squared statistic\nDegrees of freedom\np-vlaue\n\n\n\n\nFirst Leg\n10.259\n9\n0.330\n\n\nEuropean Leg\n19.554\n4\n0.001\n\n\nFinal Leg\n17.337\n16\n0.364\n\n\n\n\n\n\nTherefore, if our \\(\\chi^2\\) assumptions were met we might infer that there‚Äôs some evidence against the outfits for the European leg being random.\n\n\n\n\n\nChi-squared distribution under the NULL hypothesis for each leg along with the observed chi-squared statistic in purple."
  },
  {
    "objectID": "outfit_transitions.html#a-randomisation-test",
    "href": "outfit_transitions.html#a-randomisation-test",
    "title": "3¬† Are the surprise song outfits random?",
    "section": "3.2 A randomisation test",
    "text": "3.2 A randomisation test\nIf we‚Äôre not happy that our parametric assumptions are met then we can (often) fall back on simple resampling methods; basically simulating what would happen under chance alone and then comparing how our observed situation stack up!\nTo begin with let‚Äôs use the \\(\\chi^2\\)-squared statistic to represent the transition matrix we observed for each leg (it is a valid metric comparing between what we expected under independence and what we observed). By using a randomisation test we can build up a sampling distribution of this chosen metric that represent what would happen under chance alone (i.e., without any assumptions about the shape of this distribution). Our observed statistics in this case are given in the first column of Table¬†3.1.\n\n## create a function for the randomisation test using chi-sq\n## on the transition matrix, using a for loop just bc\n\nrandomisation &lt;- function(data, nreps = 1000, seed = 1984){\n  sampling_dist &lt;- numeric(nreps)\n  set.seed(seed) \n  for (i in 1:nreps) {\n   sampling_dist[i] &lt;- suppressWarnings(sample(data) |&gt; \n                                          transitions() |&gt; \n                                          chisq.test())$statistic\n  }\nreturn(sampling_dist)\n}\n\nCalculating a p-value (note they‚Äôre all pretty much the same as above!).\n\n## first leg\nnull_first &lt;- randomisation(first_leg)\nmean(null_first &gt;= (first_leg |&gt; transitions() |&gt; chisq.test())$statistic)\n\n[1] 0.336\n\n## European leg\nnull_mid &lt;- randomisation(mid_leg)\nmean(null_mid &gt;= (mid_leg |&gt; transitions() |&gt; chisq.test())$statistic)\n\n[1] 0.001\n\n## Final leg\nnull_final &lt;- randomisation(final_leg)\nmean(null_final &gt;= (final_leg |&gt; transitions() |&gt; chisq.test())$statistic)\n\n[1] 0.322\n\n\n\n\n\n\n\nSampling distribution of the test statistic (the chi-squared statistic) under the NULL hypothesis for each leg along with the observed test statistic in purple.\n\n\n\n\nBut, we can actually use any metric we like in a randomisation test! For our example, the \\(\\chi^2\\) is a nice (distance) statistic because it considers all the transitions, but if we were particularly interested in, say, a particular transition (e.g., Yellow \\(\\rightarrow\\) Pink for the first leg) we could look at those instead.\n\\(H_0 = \\text{A particular transition occured at random}\\)\nvs.¬†\n\\(H_1 = \\text{A particular transition occured fewer or more times than expected}\\).\n[Note: than expected means than was expected under chance alone.]\n\n## create a new function for the randomisation test using the \n## numbers of a particular transition (from --&gt; to)\n\nrandomisation &lt;- function(data, from = \"Yellow\", to = \"Pink\", \n                          nreps = 1000, seed = 1984){\n  sampling_dist &lt;- numeric(nreps)\n  set.seed(seed) \n  for (i in 1:nreps) {\n   sampling_dist[i] &lt;- (sample(data) |&gt; transitions())[from, to]\n  }\nreturn(sampling_dist)\n}\n\nCalculating a two-sided p-value.\n\n## first leg, Yellow --&gt; Pink (default)\nnull_first &lt;- randomisation(first_leg)\nobs_first &lt;- (first_leg |&gt; transitions())[\"Yellow\", \"Pink\"]\nmean(abs(null_first - mean(null_first)) &gt;= abs(obs_first - mean(null_first)))\n\n[1] 0.199\n\n## European leg, Sunset orange --&gt; Flamingo pink\nnull_mid &lt;- randomisation(mid_leg, from = \"Sunset orange\", to = \"Flamingo pink\")\nobs_mid &lt;- (mid_leg |&gt; transitions())[\"Sunset orange\", \"Flamingo pink\"]\nmean(abs(null_mid - mean(null_mid)) &gt;= abs(obs_mid - mean(null_mid)))\n\n[1] 0.766\n\n## Final leg, Blurple --&gt; Blurple\nnull_final &lt;- randomisation(final_leg, from = \"Blurple\", to = \"Blurple\")\nobs_final &lt;- (final_leg |&gt; transitions())[\"Blurple\", \"Blurple\"]\nmean(abs(null_final - mean(null_final)) &gt;= abs(obs_final - mean(null_final)))\n\n[1] 0.644\n\n\n\n\n\n\n\nSampling distribution of the test statistic (the number of times a particular transition occured) under the NULL hypothesis for each leg along with the observed test statistic in purple.\n\n\n\n\nIn each case, no evidence to suggest we see the particular transitions more or less frequently than would be expected under the NULL hypothesis of chance alone. (Note the transitions were chosen arbitrarily)",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Are the surprise song outfits random?</span>"
    ]
  },
  {
    "objectID": "outfit_transitions.html#a-likelihood-ratio-test",
    "href": "outfit_transitions.html#a-likelihood-ratio-test",
    "title": "3¬† Are the surprise song outfits random?",
    "section": "3.3 A likelihood ratio test",
    "text": "3.3 A likelihood ratio test\nWhat about using a model based approach? If the outfits were random (given the choices) then we‚Äôd expect each to occur independently of one another (i.e., the chance of one outfit is independent of any other).\nLet‚Äôs consider the first leg, defining the events mathematically we let \\(\\{X_1, X_2, \\ldots, X_n\\}\\) be the outfits taking values in \\(\\{\\text{Blue}, \\text{Green}, \\text{Pink}, \\text{Yellow}\\}\\) (i.e., four possible categories).\nIf the outfits were independent then we can write the likelihood as\n\\[L_0(p; x) = \\prod_{t=1}^{n} P(X_t = x_t) = \\prod_{j=1}^{4} p_j^{n_j}\\].\nHere \\(p_j\\) is the probability of observing category \\(j\\), \\(n_j\\) is the number of times category \\(j\\) appears from \\(t=2\\) to \\(n\\), and \\(\\sum_{j=1}^{k} p_j = 1\\). The log-likelihood is therefore \\[\\log L_0(p;x) = \\sum_{t=2}^{n} \\log p_{x_t} = \\sum_{j=1}^{4} n_j \\log p_j\\].\nCalculating this in R step-by-step\n\nn &lt;- length(first_leg)\nn\n\n[1] 81\n\nk &lt;- length(unique(first_leg))\nk\n\n[1] 4\n\nchain &lt;- as.factor(first_leg)\nchain\n\n [1] Pink   Green  Pink   Green  Green  Pink   Yellow Pink   Green  Yellow\n[11] Pink   Green  Green  Pink   Yellow Pink   Green  Yellow Pink   Yellow\n[21] Green  Yellow Green  Pink   Pink   Green  Yellow Pink   Green  Yellow\n[31] Pink   Yellow Yellow Pink   Green  Pink   Pink   Yellow Yellow Pink  \n[41] Green  Pink   Pink   Yellow Pink   Pink   Pink   Pink   Yellow Green \n[51] Blue   Blue   Pink   Green  Yellow Blue   Pink   Yellow Yellow Blue  \n[61] Green  Blue   Yellow Green  Blue   Yellow Pink   Green  Yellow Pink  \n[71] Blue   Pink   Blue   Yellow Green  Yellow Green  Pink   Pink   Yellow\n[81] Blue  \nLevels: Blue Green Pink Yellow\n\np_indep &lt;- table(chain) / n\np_indep ## independent probabilities\n\nchain\n     Blue     Green      Pink    Yellow \n0.1111111 0.2469136 0.3580247 0.2839506 \n\np_indep[as.integer(chain)] ## probabilities of each element as they occur\n\nchain\n     Pink     Green      Pink     Green     Green      Pink    Yellow      Pink \n0.3580247 0.2469136 0.3580247 0.2469136 0.2469136 0.3580247 0.2839506 0.3580247 \n    Green    Yellow      Pink     Green     Green      Pink    Yellow      Pink \n0.2469136 0.2839506 0.3580247 0.2469136 0.2469136 0.3580247 0.2839506 0.3580247 \n    Green    Yellow      Pink    Yellow     Green    Yellow     Green      Pink \n0.2469136 0.2839506 0.3580247 0.2839506 0.2469136 0.2839506 0.2469136 0.3580247 \n     Pink     Green    Yellow      Pink     Green    Yellow      Pink    Yellow \n0.3580247 0.2469136 0.2839506 0.3580247 0.2469136 0.2839506 0.3580247 0.2839506 \n   Yellow      Pink     Green      Pink      Pink    Yellow    Yellow      Pink \n0.2839506 0.3580247 0.2469136 0.3580247 0.3580247 0.2839506 0.2839506 0.3580247 \n    Green      Pink      Pink    Yellow      Pink      Pink      Pink      Pink \n0.2469136 0.3580247 0.3580247 0.2839506 0.3580247 0.3580247 0.3580247 0.3580247 \n   Yellow     Green      Blue      Blue      Pink     Green    Yellow      Blue \n0.2839506 0.2469136 0.1111111 0.1111111 0.3580247 0.2469136 0.2839506 0.1111111 \n     Pink    Yellow    Yellow      Blue     Green      Blue    Yellow     Green \n0.3580247 0.2839506 0.2839506 0.1111111 0.2469136 0.1111111 0.2839506 0.2469136 \n     Blue    Yellow      Pink     Green    Yellow      Pink      Blue      Pink \n0.1111111 0.2839506 0.3580247 0.2469136 0.2839506 0.3580247 0.1111111 0.3580247 \n     Blue    Yellow     Green    Yellow     Green      Pink      Pink    Yellow \n0.1111111 0.2839506 0.2469136 0.2839506 0.2469136 0.3580247 0.3580247 0.2839506 \n     Blue \n0.1111111 \n\np_indep[as.integer(chain)] |&gt; log() ## log probabilities of each element as they occur\n\nchain\n     Pink     Green      Pink     Green     Green      Pink    Yellow      Pink \n-1.027153 -1.398717 -1.027153 -1.398717 -1.398717 -1.027153 -1.258955 -1.027153 \n    Green    Yellow      Pink     Green     Green      Pink    Yellow      Pink \n-1.398717 -1.258955 -1.027153 -1.398717 -1.398717 -1.027153 -1.258955 -1.027153 \n    Green    Yellow      Pink    Yellow     Green    Yellow     Green      Pink \n-1.398717 -1.258955 -1.027153 -1.258955 -1.398717 -1.258955 -1.398717 -1.027153 \n     Pink     Green    Yellow      Pink     Green    Yellow      Pink    Yellow \n-1.027153 -1.398717 -1.258955 -1.027153 -1.398717 -1.258955 -1.027153 -1.258955 \n   Yellow      Pink     Green      Pink      Pink    Yellow    Yellow      Pink \n-1.258955 -1.027153 -1.398717 -1.027153 -1.027153 -1.258955 -1.258955 -1.027153 \n    Green      Pink      Pink    Yellow      Pink      Pink      Pink      Pink \n-1.398717 -1.027153 -1.027153 -1.258955 -1.027153 -1.027153 -1.027153 -1.027153 \n   Yellow     Green      Blue      Blue      Pink     Green    Yellow      Blue \n-1.258955 -1.398717 -2.197225 -2.197225 -1.027153 -1.398717 -1.258955 -2.197225 \n     Pink    Yellow    Yellow      Blue     Green      Blue    Yellow     Green \n-1.027153 -1.258955 -1.258955 -2.197225 -1.398717 -2.197225 -1.258955 -1.398717 \n     Blue    Yellow      Pink     Green    Yellow      Pink      Blue      Pink \n-2.197225 -1.258955 -1.027153 -1.398717 -1.258955 -1.027153 -2.197225 -1.027153 \n     Blue    Yellow     Green    Yellow     Green      Pink      Pink    Yellow \n-2.197225 -1.258955 -1.398717 -1.258955 -1.398717 -1.027153 -1.027153 -1.258955 \n     Blue \n-2.197225 \n\nll0 &lt;- p_indep[as.integer(chain)] |&gt; log() |&gt; sum() ## log likelihood\nll0\n\n[1] -106.4928\n\n\nNow, what about the likelihood if we assume the sequence of outfits is a first-order Markov chain (i.e., the current outfit \\(X_t\\) depends on the previous one \\(X_{t-1}\\)):\n\\[P(X_t = x_t \\mid X_{t-1} = x_{t-1}) = P_{x_{t-1}, x_t}.\\]\nHere \\(P_{i,j}\\) is the probability of transitioning from state \\(i\\) to state \\(j\\), again with \\(\\sum_{j=1}^{k} P_{i,j} = 1 \\quad \\text{for all } i\\). We can write the likelihood as\n\\[L_1(p;x_t|x_{t-1}) = \\prod_{t=2}^{n} P(X_t = x_t \\mid X_{t-1} = x_{t-1}) = \\prod_{i=1}^{k} \\prod_{j=1}^{k} P_{i,j}^{N_{i,j}}\\]\nWhere \\(N_{i,j}\\) is the number of transitions from state \\(i\\) to state \\(j\\). The log-likelihood is then\n\\[\\log(L_1(p;x_t|x_{t-1})) = \\sum_{t=2}^{n} \\log (P_{x_{t-1}, x_t}) = \\sum_{i=1}^{k} \\sum_{j=1}^{k} N_{i,j} \\log (P_{i,j})\\]\nCalculating this in R step-by-step\n\n## transition probability matrix\ntm &lt;- prop.table(transitions(first_leg), 1) ## over rows\ntm\n\n        \n               Blue      Green       Pink     Yellow\n  Blue   0.12500000 0.12500000 0.37500000 0.37500000\n  Green  0.15000000 0.10000000 0.35000000 0.40000000\n  Pink   0.06896552 0.37931034 0.24137931 0.31034483\n  Yellow 0.13043478 0.26086957 0.47826087 0.13043478\n\n## using a for loop\nll1 &lt;- 0 ## initialise\nfor(i in 2:n){\n  lli &lt;- log(tm[chain[i-1], chain[i]]) ## element of tm\n  ll1 &lt;- ll1 + lli\n}\nll1 ## log likelihood assuming a first-order Markov chain\n\n[1] -99.9088\n\n## we can benchmark using the markovchain package \nmarkovchain::markovchainFit(data = first_leg, method = \"mle\")$logLikelihood\n\n[1] -99.9088\n\n\nConstruction a likelihood ratio test statistic\n\\[\\Lambda = 2 \\left( \\log(L_1(p;x_t|x_{t-1}))  - \\log(L_0(p; x)) \\right)\\]\nUnder the NULL hypothesis \\(H_0\\), the test statistic \\(\\Lambda\\) asymptotically follows a \\(\\chi^2\\) distribution with degrees of freedom \\(\\text{df} = (k - 1)^2\\).\nIn R\n\ndelta &lt;- 2 * (ll1 - ll0)\ndf &lt;- (k - 1)^2\np_val &lt;- pchisq(delta, df, lower.tail = FALSE)\n\nNo evidence against the outfits being independent.\n\n\n\n\n\nDistribution of the test statistic under the NULL hypothesis, the observed value shown in purple.\n\n\n\n\nSo, let‚Äôs make a function.\n\nlrt &lt;- function(x, plot = FALSE){\n  ## under H0\n  n &lt;- length(x)\n  k &lt;- length(unique(x))\n  chain &lt;- as.factor(x)\n  p_indep &lt;- table(chain) / n\n  ll0 &lt;- p_indep[as.integer(chain)] |&gt; log() |&gt; sum() \n  ## first-order Markov\n  tm &lt;- prop.table(transitions(x), 1) \n  ll1 &lt;- 0 \n  for(i in 2:n){\n    lli &lt;- log(tm[chain[i-1], chain[i]]) \n    ll1 &lt;- ll1 + lli\n  }\n  ## test statistic\n  delta &lt;- 2 * (ll1 - ll0)\n  df &lt;- (k - 1)^2\n  p_val &lt;- pchisq(delta, df, lower.tail = FALSE)\n  if(plot){\n    chi &lt;- data.frame(x = seq(0, 30, length.out = 100))\n    chi$density &lt;- dchisq(chi$x, df = df)\n    chi %&gt;%\n      ggplot(aes(x = x, y = density)) +\n      geom_line(linewidth = 2) +\n      geom_vline(aes(xintercept = delta), linetype = \"dashed\", color = \"purple\") +\n      labs(title = \"\",x = \"\", y = \"\") + theme_bw() -&gt; p\n    print(p)\n  }\n  ## info to return\n  return(list(\"ll0\" = ll0,\n              \"ll1\" = ll1,\n              \"delta\" = delta,\n              \"df\" = df,\n              \"p.val\" = p_val))\n}\n\nlrt(first_leg)\n\n$ll0\n[1] -106.4928\n\n$ll1\n[1] -99.9088\n\n$delta\n[1] 13.16793\n\n$df\n[1] 9\n\n$p.val\n[1] 0.1551535\n\nlrt(mid_leg, plot = TRUE)\n\n\n\n\n\n\n\n\n$ll0\n[1] -52.30575\n\n$ll1\n[1] -39.26825\n\n$delta\n[1] 26.075\n\n$df\n[1] 4\n\n$p.val\n[1] 3.056156e-05\n\nlrt(final_leg, plot = TRUE)\n\n\n\n\n\n\n\n\n$ll0\n[1] -26.26847\n\n$ll1\n[1] -14.04639\n\n$delta\n[1] 24.44415\n\n$df\n[1] 16\n\n$p.val\n[1] 0.08024261\n\n\nFirst order Markov chain?\nSo, might we believe that for the European leg of her tour Swift‚Äôs outfits weren‚Äôt random and perhaps what she wore one night depended on her outfit the previous night (i.e., in stats speak followed a first-order Markov chain)?\n\n\n\n\n\n\nNote\n\n\n\nBasically, the first-order Markov property is that the future state of a system depends only on its current state and is independent of its past history.\n\n\n\nrequire(markovchain)\nverifyMarkovProperty(mid_leg) ## no evidence against the Markov property p-value 0.834 (~likely a Markov chain?)\n\nTesting markovianity property on given data sequence\nChi - square statistic is: 7.339583 \nDegrees of freedom are: 12 \nAnd corresponding p-value is: 0.8343811 \n\nmarkovchainFit(data = mid_leg, method = \"mle\") ## as above but with ses :)\n\n$estimate\nMLE Fit \n A  3 - dimensional discrete Markov Chain defined by the following states: \n Flamingo pink, Ocean blue, Sunset orange \n The transition matrix  (by rows)  is defined as follows: \n              Flamingo pink Ocean blue Sunset orange\nFlamingo pink    0.06666667  0.2666667     0.6666667\nOcean blue       0.57142857  0.0000000     0.4285714\nSunset orange    0.27777778  0.5555556     0.1666667\n\n\n$standardError\n              Flamingo pink Ocean blue Sunset orange\nFlamingo pink    0.06666667  0.1333333    0.21081851\nOcean blue       0.20203051  0.0000000    0.17496355\nSunset orange    0.12422600  0.1756821    0.09622504\n\n$confidenceLevel\n[1] 0.95\n\n$lowerEndpointMatrix\n              Flamingo pink  Ocean blue Sunset orange\nFlamingo pink    0.00000000 0.005338081    0.25346989\nOcean blue       0.17545597 0.000000000    0.08564909\nSunset orange    0.03429924 0.211224910    0.00000000\n\n$upperEndpointMatrix\n              Flamingo pink Ocean blue Sunset orange\nFlamingo pink     0.1973310  0.5279953     1.0000000\nOcean blue        0.9674012  0.0000000     0.7714938\nSunset orange     0.5212563  0.8998862     0.3552643\n\n$logLikelihood\n[1] -39.26825\n\n\nWhat about 1st vs 2nd Markov Chain\n\n## Let's trick markovchain into doing this for us\n## by creating a \"first order\" chain which is actually of order 2\n\nsnap &lt;- data.frame(current = mid_leg)\nsnap$future &lt;- lead(snap$current, 1)\nsnap$past &lt;- lag(snap$current, 1)\n\nsec_order &lt;- snap |&gt;\n  filter(!is.na(future) & !is.na(past)) %&gt;%\n  tidyr::unite(\"y_current\", c(\"past\", \"current\"), remove = FALSE) |&gt;\n  mutate(y_next = lead(y_current, 1),\n         y_previous = lag(y_current, 1))\n\nll1 &lt;- markovchainFit(data = mid_leg, method = \"mle\")$logLikelihood\nll1\n\n[1] -39.26825\n\nll2 &lt;- markovchainFit(data = sec_order$y_current, method = \"mle\")$logLikelihood\nll2 ## eyeballing this, looks pretty similar to 1st order\n\n[1] -32.29189\n\n\nFor fun let‚Äôs also calculate the 2nd order Markov Chain likelihood manually.\n\n## function to calculate the log likelihood assuming a second-order Markov chain\nll2 &lt;- function(x){\n  n &lt;- length(x)\n  k &lt;- length(unique(x))\n  chain &lt;- as.factor(x)\n  ## Initialize 3D transition count array\n  counts &lt;- array(0, dim = c(k, k, k))\n  int &lt;- as.integer(chain)\n  for (t in 3:n) {\n    a &lt;- int[t - 2]\n    b &lt;- int[t - 1]\n    c &lt;- int[t]\n    counts[a, b, c] &lt;- counts[a, b, c] + 1\n    }\n  ## Calculate conditional probabilities\n  probs &lt;- counts\n  for (a in 1:k) {\n    for (b in 1:k) {\n      total &lt;- sum(counts[a, b, ])\n    if (total &gt; 0) {probs[a, b, ] &lt;- counts[a, b, ] / total}\n      }\n    }\n  ll &lt;- 0\n  for (t in 3:n) {\n    a &lt;- int[t - 2]\n    b &lt;- int[t - 1]\n    c &lt;- int[t]\n    p &lt;- probs[a, b, c]\n    if (p &gt; 0) {ll &lt;- ll + log(p)}\n  }\n  return(ll)\n}\n## 2nd order Markov Chain log-likelihood\nll2(mid_leg)\n\n[1] -32.88436",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Are the surprise song outfits random?</span>"
    ]
  },
  {
    "objectID": "colour_sentiments.html#chi2-test-for-equal-proportions",
    "href": "colour_sentiments.html#chi2-test-for-equal-proportions",
    "title": "4¬† Colour Sentiments",
    "section": "4.1 \\(\\chi^2\\) test for equal proportions",
    "text": "4.1 \\(\\chi^2\\) test for equal proportions\n\ncolorSentimentScores$colourGroup <- colorGroups[colorSentimentScores$colour]\ncols.df <- as.data.frame.matrix(table(colorSentimentScores$colourGroup, colorSentimentScores$meaning))\ncols.df\n\n                negative neutral positive\nblack and white        2       2        0\nblacks                 3       7        3\nblues                 18       7       10\ncolorful               1       3       11\ngreens                 0       3        8\npurples                1       1        4\nreds                  15      11       13\nwhites                13      12        5\nyellows                1       9       17\n\n## change col and row names for aesthetic reasons\ncolnames(cols.df) <- str_to_title(colnames(cols.df))\nrownames(cols.df) <- str_to_title(rownames(cols.df))\nrow.props <- prop.table(as.matrix(cols.df), margin = 1)\ncorrplot(row.props, is.corr = FALSE, cl.pos = FALSE)\n\n\n\n\nThe plot above is not a traditional correlation plot, rather each entry is the row-wise proportion of colour mentions across each sentiment. The shade and size of each circle represent the magnitude of each entry, where darker and larger circles correspond to larger row-wise proportions. Evident from this plot is that for Yellows, Purples, Greens and Colorful we see a higher proportion of mentions associated with Positive sentiment.\nBelow we carry out a (Pearson‚Äôs) chi-squared test where the null hypothesis is that the joint distribution of the cell counts is the product of the row and column marginals:\n\\(H0\\): colours and sentiments are independent vs \\(H1\\): colours and sentiments are dependent,\n\n## chi-squared test\nchi <- chisq.test(cols.df)\nchi ## strong evidence against NULL\n\n\n    Pearson's Chi-squared test\n\ndata:  cols.df\nX-squared = 47.661, df = 16, p-value = 5.369e-05\n\ncorrplot(chi$residuals, is.corr = FALSE, cl.pos = FALSE)\n\n\n\n\nAgain, the plot above is not a traditional correlation plot, each entry is the \\(\\chi^2\\) residual (i.e., a measure of deviation from the expected). Red hues indicate fewer than expected counts, and blue hues indicate higher counts than were expected. The sizes and shade of each circle reflect the magnitude of the deviation. Looking at the Yellow row we see that we observe far fewer mentions with negative sentiment and more mentions with positive sentiment, than we might expect under equal counts. Referring back to the table of counts this is clear to see."
  },
  {
    "objectID": "colour_sentiments.html#correspondence-analysis",
    "href": "colour_sentiments.html#correspondence-analysis",
    "title": "4¬† Colour Sentiments",
    "section": "4.2 Correspondence analysis",
    "text": "4.2 Correspondence analysis\nSo, as we suspected from the table alone it seems likely that there is some dependence between colour mentions (in Taylor‚Äôs lyrics) and the sentiment of the lyrics. What we‚Äôd like to do is further delve into the association between colours and their associated sentiment in Taylor‚Äôs lyrics. To do this we can carry out correspondence analysis (CA):\n\ncoa &lt;- FactoMineR::CA(cols.df)\n\n\n\n\n\n\n\n\nThe biplot above shows the relative positions of the rows (colours) and the columns (sentiments). This is not a typical scatter plot and distances* between points cannot neccesarily be interpreted as you would do if it were. Now, we are not interested in representing the contingency table above in a lower dimension space using correspondence analysis. Rather, we are interested in the relative associations between colours and sentiment. The plot above is termed a symmetric plot and shows a global pattern: the distance between any row points (colours) or column points (sentiments) gives a measure of their similarity or dissimilarity, we cannot from this plot compare associations between colours and sentiments directly. However, in general we can see that Yellows, Purples, Greens and Colorful are mainly mentioned in association with Positive sentiments etc.\nIn order to interpret the distance between sentiments and colours we need to use an asymmetric biplot (see below).\nFirst, let‚Äôs describe each dimension. (Note this should be done with care! Avoid reification (i.e., reading something tangible into the dimensions)). We are particularly interested in the sentiments (i.e., column variables) representation of the dimenesions.\n\ncoa$col$coord\n\n               Dim 1      Dim 2\nNegative  0.60492700 -0.1746621\nNeutral   0.07774606  0.3226498\nPositive -0.52031114 -0.1170984\n\n## plotting\ndata.frame(coa$col$coord) %&gt;%\n  mutate(variables = rownames(.)) %&gt;%\n  pivot_longer(., cols = 1:2) %&gt;%\n  ggplot(aes(value, variables, fill = value)) +\n  geom_col() +\n  geom_vline(xintercept = 0, lty = \"dashed\", col = \"darkgrey\", linewidth = 2) +\n  facet_wrap(~name, scales = \"free_y\") +\n    labs(fill = \"Relative\\ncontribution\",y = NULL, x = NULL) +\n  theme_bw() + scale_fill_gradient2(low = \"darkblue\", mid = \"white\",high = \"darkred\")\n\n\n\n\n\n\n\n\nEach panel of the plot above shows the relative contribution of sentiments to each new dimension. The size and shade of each bar represents the magnitude of the contribution. The vertical grey line (at 0) highlights the direction of the contributions.\nTherefore (roughly speaking) lower -ve values in Dim 1 are more Positive in sentiment and +ve values are more Negative (values close to 0 are Neutral). The absolute direction of the values here are meaningless; it is the relative direction we are interested in, and so Dim 1 can be thought of as a measure of either Positive or Negative sentiment (let‚Äôs call it feeling). Dim 2 might be thought of as conviction of sentiment (or feeling), higher values reflecting Neutral feelings.\nNow, let‚Äôs look the degree of association between the rows (colours) and the axes. The returned cos2 measure represents the quality of representation (i.e., degree of association), it takes values between 0 and 1.\n\ncoa$row$cos2\n\n                     Dim 1        Dim 2\nBlack And White 0.81876976 0.1812302419\nBlacks          0.06600422 0.9339957761\nBlues           0.66084920 0.3391507987\nColorful        0.95390800 0.0460919952\nGreens          0.99970382 0.0002961754\nPurples         0.80178643 0.1982135704\nReds            0.85809051 0.1419094921\nWhites          0.88762796 0.1123720391\nYellows         0.95677338 0.0432266171\n\ncorrplot(coa$row$cos2, is.corr = FALSE, cl.pos = FALSE)\n\n\n\n\n\n\n\n\nAgain, this is not a traditional correlation plot. Each entry represents the association between the colours (row vaiables) and the dimensions. From this all colours (bar Blacks) are strongly associated with the feelings dimension. Mentions of the Blacks colour groupings are more associated with Dim 2 the conviction dimension; this, is also evident from the contingency table above where most mentions of this group were associated with Neutral sentiments.\nIdeally, what we‚Äôd like to do is both compare the association between colour groups AND the associations between colour groups and sentiments. To do this we create an asymmetric biplot and represent columns (sentiment) in row (colours) in space (by setting map = \"rowprincipal\" in the call to fviz_ca_biplot() below). Doing this also better shows the relationships between the colours.\nrowprincipal normalization: the distances between the row labels are meaningful and consistent with those shown in the principal normalization, but the differences between the column coordinates are now misleading. columnprincipal: the distances between the row points are not correct\n\n## row/colour contribution asymmetric biplot \nfviz_ca_biplot(coa, repel = TRUE, col.col = \"brown\", col.row = \"purple\",\n               map = \"rowprincipal\", arrows = c(TRUE,TRUE)) + ggtitle(\"\") +\n  theme_void()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n‚Ñπ Please use `linewidth` instead.\n‚Ñπ The deprecated feature was likely used in the ggpubr package.\n  Please report the issue at &lt;https://github.com/kassambara/ggpubr/issues&gt;.\n\n\n\n\n\n\n\n\n\nAdding arrows to the biplot let‚Äôs us assess the degree of association between colours and sentiments. Again, this is not a typical scatter plot! An acute angle between two arrows indicates a strong association between the corresponding row (colour) and column (sentiment). From the plot above Purples have the strongest association with Positive sentiment, Reds & Blues with Negative and Blacks with Neutral. In summary, acute angles between colours and sentiment suggest positive association, right angles suggest independence, and obtuse angles suggest negative association.\n\n4.2.1 Customising the biplot\n\n## rows - flip around so that dim 1 is \"-ve --&gt; +ve\"\ncoords &lt;-  coa$row$coord  %*% diag(c(-1,1)) |&gt; as.data.frame()\ncolnames(coords) &lt;- c(\"x\",\"y\")\ncoords$count &lt;- rowSums(cols.df)\ncoords$colourGroup &lt;- tolower(rownames(coords))\ncoords$colourGroupHex &lt;- colorPaletteGroups[coords$colourGroup]\n## cols - flip around so that dim 1 is \"-ve --&gt; +ve\"\ncoos &lt;-  coa$col$coord %*% diag(c(-1,1)) |&gt; as.data.frame()\ncolnames(coos) &lt;- c(\"x\",\"y\")\ncoos$sent &lt;- str_to_title(rownames(coos)) \n\ncols &lt;- colorSentimentScores %&gt;% select(colour, colourGroup) %&gt;%\n    group_by(colourGroup) %&gt;% mutate(count = n()) %&gt;% ungroup() |&gt; unique()\n\ndat &lt;- left_join(cols, coords)\ndat$colorPaletteColours &lt;- colorPaletteColours[dat$colour]\n\nggplot(dat, aes(x = x, y = y,  group = colourGroup)) +\n    geom_point(data = coords, aes(x = x, y = y, col = colourGroupHex), alpha = 0.4, size = 5, pch = 18) +\n    geom_segment(data = coords, aes(x = 0, y = 0, xend = x, yend = y, col = colourGroupHex),\n                 inherit.aes = FALSE,\n               arrow = arrow(length = unit(0.3, \"cm\")), alpha = 0.3) +\n    geom_text_repel(aes(label = colour, col = colorPaletteColours),\n                    max.overlaps = 100, box.padding = 0.1, segment.alpha = 0.3) +\n    geom_text(data = coos, aes(x = x, y = y, label = sent), inherit.aes = FALSE, size = 5, col = \"darkgrey\") +\n    geom_vline(xintercept = 0, linetype = \"dashed\", color = \"gray\", linewidth = 0.5) +\n      geom_hline(yintercept = 0, linetype = \"dashed\", color = \"gray\", linewidth = 0.5) +\n    theme_bw() + scale_color_identity() +\n    theme(panel.background = element_rect(fill = \"oldlace\", color = NA),\n          axis.line.x = element_blank(), panel.border = element_blank()) +\n    xlab(\"Dim 1 (82.5%)\") + ylab(\"Dim 2 (17.5%)\")  + coord_fixed()\n\n\n\n\n\n\n\n\n\n\n4.2.2 Reducing dimensions\nIt‚Äôs not like we have swaths of variables! But, let‚Äôs explore! We saw from above that each colour (bar Blacks) was strongly associated with the first dimension (i.e., feelings). Below we look as the percentage of variation explained by each dimension.\n\ncoa$eig\n\n      eigenvalue percentage of variance cumulative percentage of variance\ndim 1 0.21841337                82.4876                           82.4876\ndim 2 0.04636992                17.5124                          100.0000\n\n\nDim 1 (i.e., feelings) explains ~82% of the total variation. Pretty much most of it! This makes sense as it is basically a rotation of the linear sentiment scale we initially assumed when scoring the lyrics! Let‚Äôs have a look as this one dimension on it‚Äôs own, recall that we‚Äôd like to do this and examining the association between colours (i.e., a sapce that represent columns (sentiment) in row (colours) in space).\n\n## grabbing coordinates from `rowprincipal` plot\np &lt;- fviz_ca_biplot(coa, map = \"rowprincipal\")\ntmp &lt;- ggplot_build(p)\nro &lt;- tmp$data[[2]][,c(1,2,3)]  \nro$colour &lt;- colorPaletteGroups[tolower(ro$label)]\nsents &lt;- tmp$data[[6]][, c(1, 2, 3)]\n\n## atan2 counterclockwise\nangles &lt;- function(rows, cols, row_names, col_names){\n  res &lt;- matrix(0, nrow = nrow(rows), ncol = nrow(cols))\n  for(i in 1:nrow(cols)){\n    angle = atan2(cols[i, 2], cols[i, 1]) - atan2(rows[,2], rows[,1]) \n    ## make between -pi (-180) and pi (180)\n    angle = ifelse(angle &gt; pi, angle - (2*pi), ifelse(angle &lt;= -pi, angle + (2*pi), angle)) *(180/pi)\n    res[, i] = angle\n  }\n  rownames(res) &lt;- row_names\n  colnames(res) &lt;- col_names\n  return(res)\n}\n## 'distances' between rows and cols in row space\nrc &lt;- angles(ro[, 1:2], cols = sents[,1:2], row_names = ro$label, col_names = sents$label)\n## plotting relative to neutral\nrcls &lt;- data.frame(x = rc[,2], col = ro$colour, lab = ro$label)\n## 'distances' between cols in row space (i.e., standard)\ncc &lt;- angles(sents[,1:2], cols = sents[,1:2], row_names = sents$label, col_names = sents$label)\nccls &lt;- data.frame(x = cc[,2], lab = sents$label)\n## plot on the \"angle\" line\nggplot(rcls, aes(x = x, y = 1, col = col, label = lab)) +\n  geom_point() + \n  ggrepel::geom_text_repel(aes(col = col), box.padding = 1.5, \n                            arrow = arrow(length = unit(0.1, \"inches\")), alpha = 0.7, size = 4) +\n  scale_color_identity() +\n  geom_hline(yintercept = 1, alpha = 0.3, col = \"grey\") +\n  geom_text(data = ccls, size = 6, col = \"darkgrey\") + theme_void() +\n geom_text(data = data.frame(x = c(-180, 180), y = 1, label = c(\"-pi\", \"pi\")), \n            aes(label = label),\n            col = \"grey\", parse = TRUE) +\n  theme(panel.background = element_rect(fill = \"oldlace\"))\n\n\n\n\n\n\n\n\nThe plot above is a 1D representation of the angles between colours and sentiments following the rowprinciple. Clearly Blues and Reds are strongly associated with Negative and Blacks are mostly Neutral etc. Note that this plot is relative to Neutral sentiment.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Colour Sentiments</span>"
    ]
  },
  {
    "objectID": "colour_sentiments.html#cluster-analysis-of-ca-colour-scores",
    "href": "colour_sentiments.html#cluster-analysis-of-ca-colour-scores",
    "title": "4¬† Colour Sentiments",
    "section": "4.3 Cluster analysis of CA colour scores",
    "text": "4.3 Cluster analysis of CA colour scores\nRecall, we are interetsted in the association between colours. Having carried out CA, we have a decent idea of which colours are associated with what semtiments etc. The representation of our colours in reduced dimensinal space are:\n\ncoa$row$coord\n\n                     Dim 1       Dim 2\nBlack And White  0.7303704  0.34361934\nBlacks           0.1313584  0.49413385\nBlues            0.3808608 -0.27284216\nColorful        -0.6968777 -0.15318495\nGreens          -0.7643240  0.01315577\nPurples         -0.4987625 -0.24798828\nReds             0.1736515 -0.07061839\nWhites           0.4418876  0.15722641\nYellows         -0.5975927  0.12702125\n\ncorrplot(coa$row$coord, is.corr = FALSE, cl.pos = FALSE)\n\n\n\n\n\n\n\n\nRecall from above, we loosely termed Dim1 a measure of feeling (higher values were more Negative) and Dim2 (higher values were more Neutral) a measure of conviction. From the plot above (not a traditional correlation plot) we could infer that Greens were typically associated with strong Positive feelings and Blues with weak Negative feelings and weak convictions (i.e., not-neutral).\n\ndata &lt;- coa$row$coord\n\n## k-means clustering\nset.seed(4321)\n## two clusters\nk2 &lt;- kmeans(data, centers = 2, nstart = 25)\n## three clusters\nk3 &lt;- kmeans(data, centers = 3, nstart = 25)\n## four clusters\nk4 &lt;- kmeans(data, centers = 4, nstart = 25)\n## five clusters\nk5 &lt;- kmeans(data, centers = 5, nstart = 25)\n## six clusters\nk6 &lt;- kmeans(data, centers = 6, nstart = 25)\n\nRather than delve straight into deciding ‚Äúhow many‚Äù clusters are appropriate let‚Äôs first look at how the colour groupings/clusters change based on our choice of cluster numbers. An alluvial plot shows these transitions nicely, although a bit of set-up is required first! Recall that these clusters are based on the CA coordinates of the colours in what we termed1 feeling and conviction space.\n\nclusters &lt;- data.frame(k2$cluster, k3$cluster, k4$cluster, k5$cluster, k6$cluster)\nclusters &lt;- clusters[c(2, 1, 8, 3, 7, 4, 6, 9, 5),]\nnames(clusters) &lt;- paste(2:6, \"clusters\")\nclusters$Group &lt;- rownames(clusters)\n#clusters$cols &lt;- colorPaletteGroups[tolower(clusters$Group)]\nnames(colorPaletteGroups) &lt;- str_to_title(names(colorPaletteGroups))\n\n# Plot as alluvial\nggplot(clusters,\n       aes(axis1 = `2 clusters`, axis2 = `3 clusters`, axis3 = `4 clusters`,\n           axis4 = `5 clusters`, axis5 = `6 clusters`, y = 1)) +\n  geom_alluvium(aes(fill = Group), width = 1/12, alpha = 0.9, col = \"lightgrey\") +\n  scale_fill_manual(values = colorPaletteGroups, name = \"\") + \n  geom_stratum(width = 1/12, fill = \"pink\", color = \"orchid4\", linewidth = 1.2) +\n  #geom_text(stat = \"stratum\", aes(label = after_stat(stratum))) +\n  theme_void() + theme(legend.position = \"top\")\n\n\n\n\n\n\n\n\nEach stratum (pink box) represents the number of clusters set from two (far left) to six (far right). These clusters were estimated based on the distances in CA score space where the variables were abstract constructs, which we termed feeling and conviction. That aside, we can see from this alluvial plot which colour groupings are close toegther in this space, and when the split in each cluster occurs. Following Yellows, Purples, Greens and Colorful (which from the start we saw were all closely related with Positive sentiments), when we force the algorithm to choose five clusters, Yellows & Greens separate from Purples & Colorful, whcih by looking at the asymmetric biplot makes sense, despite the clear close association between the four colour groups in the sentiment space, the further subsetting splits according to the maximum distance in this space.\nIf we really want ro choose an appropriate number of clusters then we can use the total within cluster sums of squares (SS), which we‚Äôd like to minimize!\n\n## \"best\" representation using a rather 'adhoc'\n## total within SS\nbarplot(c(k2$tot.withinss,k3$tot.withinss,k4$tot.withinss,\n          k5$tot.withinss, k6$tot.withinss),\n        names = paste(2:6,\" clusters\"))\n\n\n\n\n\n\n\n\nThis is a rather ‚Äòad hoc‚Äô method, but from the barplot we cannot see much relative tangible reduction in SS after three (maybe four) clusters. So, let‚Äôs look at these below.\n\nfviz_cluster(k3, data = data) + theme_bw()\n\n\n\n\n\n\n\n\nMakes sense based on even our initial CA biplot! Alternatively, we cn use HCPC, which performs agglomerative hierarchical clustering on CA results.\n\nhcpc &lt;- HCPC(coa, cluster.CA = \"rows\", nb.clust = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot(hcpc,choice = \"3D.map\")\n\n\n\n\n\n\n\nplot(hcpc,choice = \"tree\")\n\n\n\n\n\n\n\n\n\n\n\n\n‚ÄúBillboard Hot 100‚Ñ¢.‚Äù n.d. https://www.billboard.com/charts/hot-100/.\n\n\nBortoli, Mario De, and Jes√∫s Maroto. 2001. ‚ÄúColours Across Cultures: Translating Colours in Interactive Marketing Communications.‚Äù In European Languages and the Implementation of Communication and Information Technologies (Elicit) Conference.\n\n\nKaufman, Gil. 2025. ‚ÄúOrange You Glad Taylor Swift Is Back?‚Äù Billboard, August. https://www.billboard.com/music/pop/taylor-orange-life-showgirl-album-memes-elmo-target-brands-1236042681/.\n\n\nOlson, Samantha. 2022. ‚ÄúAll the Easter Eggs in Taylor Swift‚Äôs Bejeweled Music Video.‚Äù Seventeen, October. https://www.seventeen.com/celebrity/music/a41766334/taylor-swift-bejeweled-music-video-easter-eggs/.\n\n\nRinker, Tyler W. 2021. ‚ÄúSentimentr: Calculate Text Polarity.‚Äù\n\n\nRowley, Glenn. 2023. ‚ÄúTaylor Swift‚Äôs the Eras Tour Easter Eggs: Here‚Äôs What Fans Have Spotted.‚Äù Billboard, May. https://www.billboard.com/lists/taylor-swift-eras-tour-easter-eggs/the-red-taylors-version-t-shirt/.\n\n\nSavage, Mark. 2024. ‚ÄúTaylor Swift: As the Eras Tour Bows Out, What Will She Do Next?‚Äù BBC, December. https://www.bbc.com/news/articles/ckg1r0v838vo.\n\n\nThompson, W Jake. 2025. ‚ÄúTaylor: Lyrics and Song Data for Taylor Swift‚Äôs Discography.‚Äù",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Colour Sentiments</span>"
    ]
  },
  {
    "objectID": "lyric_sentiments.html",
    "href": "lyric_sentiments.html",
    "title": "5¬† Lyric Sentiments",
    "section": "",
    "text": "require(sentimentr)\nrequire(taylor)\nrequire(ggrepel)\n\n\n## taylor_album_songs from taylor package\nlyrics_df &lt;- taylor_album_songs %&gt;%\n  unnest(lyrics) %&gt;%\n  select(album_name, track_name, track_number, line, lyric, element)\n\nlyrics_df$row_id &lt;- 1:nrow(lyrics_df)\n\nsentences_with_id &lt;- get_sentences(lyrics_df$lyric, lyrics_df$row_id) # this processes\n## each line as its own sentence as it's using the row_id. \nsentiment_with_id &lt;- sentiment(sentences_with_id)\nsentiment_summary &lt;- sentiment_with_id %&gt;%\n  group_by(element_id) %&gt;%\n  summarise(\n    avg_sentiment = mean(sentiment, na.rm = TRUE),\n    word_count = sum(word_count)\n  )\n\n## Join\n\nlyrics_sentiment &lt;- lyrics_df %&gt;%\n  left_join(sentiment_summary, by = c(\"row_id\" = \"element_id\"))\n## Aggregate by song to get net sentiment score\nsong_sentiment_scores_sentimentr &lt;- lyrics_sentiment %&gt;%\n  group_by(track_number, track_name, album_name) %&gt;%\n  summarize(\n    sum_sentiment = sum(avg_sentiment),\n    total_sentiment_words = n(),\n    avg_sentiment = sum(avg_sentiment) / n(), \n    .groups = \"drop\"\n  )\n\n\nalbumOrder &lt;- c(\"Taylor Swift\", \"Fearless (Taylor's Version)\", \n                \"Speak Now (Taylor's Version)\", \"Red (Taylor's Version)\",\n                \"1989 (Taylor's Version)\", \"Reputation\", \"Lover\",\n                \"folklore\", \"evermore\", \"Midnights\",\n                \"THE TORTURED POETS DEPARTMENT\")\n\nlyrics_sentiment &lt;- lyrics_sentiment %&gt;%\n  mutate(album_name = factor(album_name, levels = albumOrder))\nlyrics_sentiment &lt;- lyrics_sentiment %&gt;%\n  filter(!is.na(album_name))\n\n\n## Plot the net sentiment scores\nggplot(lyrics_sentiment, aes(x = track_number, y = avg_sentiment, fill = album_name)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~album_name, ncol = 3, scales = \"free\") +\n  scale_fill_manual(values = colorPaletteAlbums) +\n  theme_minimal() +\n  labs(\n    title = \"The emotional spectrum across Taylor Swift's discography\",\n    x = \"Track Number\",\n    y = \"Net Sentiment (Positive - Negative Words)\"\n  ) +\n  theme(plot.title = element_text(hjust=0.5))\n\n\n\n\n\n\n\n\n\nsong_sentiment_scores_sentimentr &lt;- lyrics_sentiment %&gt;%\n  group_by(track_number, track_name, album_name) %&gt;%\n  summarize(\n    sum_sentiment = sum(avg_sentiment),\n    total_sentiment_words = n(),\n    avg_sentiment = sum(avg_sentiment) / n(), \n    .groups = \"drop\"\n  )\n\nsurpriseSongsDressColours &lt;- surpriseSongsDressColours %&gt;%\n  mutate(DressColourGroup = case_when(\n    DressName %in% c(\"Pink\", \"Flamingo pink\") ~ \"Reds\",\n    DressName %in% c(\"Blue\", \"Ocean blue\") ~ \"Blues\",\n    DressName %in% c(\"Yellow\", \"Sunset orange\") ~ \"Yellows\",\n    DressName %in% c(\"Cotton candy\", \"Grapefruit\", \"Popsicle\") ~ \"Colourful\",\n    DressName == \"Blurple\" ~ \"Purples\",\n    DressName == \"Green\" ~ \"Greens\"\n  ))\n\ndress_song_sentiment_scores_sentimentr &lt;- surpriseSongsDressColours %&gt;%\n  left_join(song_sentiment_scores_sentimentr, by = c(\"Song title\" = \"track_name\")) %&gt;%\n  filter(!is.na(avg_sentiment))  \n\ndress_group_sentiments &lt;- dress_song_sentiment_scores_sentimentr %&gt;%\n  group_by(DressColourGroup) %&gt;%\n  summarise(\n    performance_weighted_sentiment = mean(avg_sentiment, na.rm = TRUE),\n    n_performances = n(),\n    .groups = 'drop'\n  )\n\n\n## recall the CA from before\ncolorSentimentScores$colourGroup &lt;- colorGroups[colorSentimentScores$colour]\ncols.df &lt;- as.data.frame.matrix(table(colorSentimentScores$colourGroup, colorSentimentScores$meaning))\ncoa &lt;- FactoMineR::CA(cols.df)\n\n\n\n\n\n\n\n## here we flip so that dim 1 is \"-ve --&gt; +ve\"\ncolour_coa_table &lt;- coa$row$coord %*% diag(c(-1,1)) |&gt;\n  as.data.frame() |&gt;\n  rownames_to_column(\"colour_category\") |&gt;\n  select(colour_category, colour_sentiment = V1) |&gt;\n  as_tibble()\n\n\ncolour_sentiments &lt;- colour_coa_table %&gt;%\n  mutate(\n    DressColourGroup = case_when(\n      colour_category == \"blues\" ~ \"Blues\",\n      colour_category == \"colorful\" ~ \"Colourful\", \n      colour_category == \"greens\" ~ \"Greens\",\n      colour_category == \"purples\" ~ \"Purples\",\n      colour_category == \"reds\" ~ \"Reds\",\n      colour_category == \"yellows\" ~ \"Yellows\",\n      TRUE ~ NA_character_\n    )\n  ) %&gt;%\n  filter(!is.na(DressColourGroup))\n\ndress_group_sentiments &lt;- dress_song_sentiment_scores_sentimentr %&gt;%\n  group_by(DressColourGroup) %&gt;%\n  summarise(\n    performance_weighted_sentiment = mean(avg_sentiment, na.rm = TRUE),\n    n_performances = n(),\n    .groups = 'drop'\n  )\n\ncombined_analysis &lt;- dress_group_sentiments %&gt;%\n  left_join(colour_sentiments, by = \"DressColourGroup\") %&gt;%\n  select(DressColourGroup, performance_weighted_sentiment, colour_sentiment, n_performances)\n\nLet‚Äôs plot.\n\nsong_performance_counts &lt;- dress_song_sentiment_scores_sentimentr %&gt;%\n  group_by(`Song title`, DressColourGroup) %&gt;%\n  summarise(\n    avg_sentiment = first(avg_sentiment),  \n    performance_count = n(),              \n    .groups = 'drop'\n  )\n\nplot_data &lt;- song_performance_counts %&gt;%\n  left_join(colour_sentiments, by = \"DressColourGroup\") %&gt;%\n  filter(!is.na(colour_sentiment))  \n\n\n## Top songs (highest sentiment) for each color group\ntop_songs &lt;- plot_data %&gt;%\n  group_by(DressColourGroup) %&gt;%\n  slice_max(avg_sentiment, n = 1, with_ties = FALSE) %&gt;%\n  ungroup()\n\n## Bottom songs (lowest sentiment) for each color group  \nbottom_songs &lt;- plot_data %&gt;%\n  group_by(DressColourGroup) %&gt;%\n  slice_min(avg_sentiment, n = 1, with_ties = FALSE) %&gt;%\n  ungroup()\n\n## Medium songs (closest to median for each color group)\nmedium_songs &lt;- plot_data %&gt;%\n  group_by(DressColourGroup) %&gt;%\n  mutate(\n    median_sentiment = median(avg_sentiment, na.rm = TRUE),\n    distance_from_median = abs(avg_sentiment - median_sentiment)\n  ) %&gt;%\n  slice_min(distance_from_median, n = 1, with_ties = FALSE) %&gt;%  # Closest to median per color (medium)\n  ungroup()\n\nhighlight_songs &lt;- bind_rows(\n  top_songs,\n  bottom_songs,\n  medium_songs) %&gt;%\n  distinct(`Song title`, DressColourGroup, .keep_all = TRUE)\n\n\nggplot(plot_data, aes(x = colour_sentiment, y = avg_sentiment)) +\n   geom_point(aes(size = performance_count, colour = tolower(DressColourGroup)), \n             alpha = 0.4, stroke = 0.8) +\n    geom_point(data = highlight_songs,\n             aes(size = performance_count, colour = tolower(DressColourGroup)), \n             alpha = 0.9, stroke = 1.5) +\n    geom_text_repel(data = highlight_songs,\n                  aes(label = `Song title`, colour = tolower(DressColourGroup)), \n                  size = 6, \n                  max.overlaps = Inf,\n                  box.padding = 0.5,\n                  point.padding = 0.3,\n                  min.segment.length = 0.1,\n                  show.legend = FALSE) +\n  scale_size_continuous(name = \"Performance\\nCount\", \n                        range = c(2, 12),\n                        breaks = c(1, 2, 3, 4, 5),\n                        guide = guide_legend(override.aes = list(alpha = 1))) +\n  scale_colour_manual(values = colorPaletteGroups,\n                      name = \"Dress colour\\nGroup\") +\n    labs(title = \"\",\n       subtitle = \"\",\n       x = \"Dress Colour Sentiment\",\n       y = \"Lyric Sentiment\",\n       caption = \"\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_blank(),\n    axis.title.x = element_text(size = 16, \n                                margin = margin(t = 10)),\n    axis.title.y = element_text(size = 16),\n    axis.text = element_text(size = 14),\n    legend.title = element_text(size = 12),\n    legend.text = element_text(size = 11),\n    legend.position = \"bottom\",\n    legend.box = \"horizontal\"\n  )\n\n\n\n\n\n\n\n\nWhat about group-wise correlation?\n\n## We only have 6 observations, not great, but let's go ahead anyway!\n## Pearson's correlation\ncor.test(combined_analysis$performance_weighted_sentiment, \n                             combined_analysis$colour_sentiment)\n\n\n    Pearson's product-moment correlation\n\ndata:  combined_analysis$performance_weighted_sentiment and combined_analysis$colour_sentiment\nt = -5.4996, df = 4, p-value = 0.005329\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.9935629 -0.5403340\nsample estimates:\n       cor \n-0.9397859 \n\n## Spearman's correlation\ncor.test(combined_analysis$performance_weighted_sentiment, \n                             combined_analysis$colour_sentiment,\n                             method = \"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  combined_analysis$performance_weighted_sentiment and combined_analysis$colour_sentiment\nS = 54, p-value = 0.2972\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n       rho \n-0.5428571 \n\n## Spearman's correlation with 95% CIs\ncorrelation::cor_test(data = combined_analysis,\n                      x = \"performance_weighted_sentiment\", \n                      y = \"colour_sentiment\",\n                      method = \"spearman\")\n\nParameter1                     |       Parameter2 |   rho |        95% CI\n-------------------------------------------------------------------------\nperformance_weighted_sentiment | colour_sentiment | -0.54 | [-0.94, 0.51]\n\nParameter1                     |     S |     p\n----------------------------------------------\nperformance_weighted_sentiment | 54.00 | 0.266\n\nObservations: 6",
    "crumbs": [
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Lyric Sentiments</span>"
    ]
  },
  {
    "objectID": "viz.html",
    "href": "viz.html",
    "title": "2¬† Visualizing the data",
    "section": "",
    "text": "The most worn looks\nCode\n## map hex colour to outfit\ndressColorMapping &lt;- unique(surpriseSongsDressColours %&gt;% select(DressName, ColourHex1))\ncolorPaletteDresses &lt;- setNames(dressColorMapping$ColourHex1, dressColorMapping$DressName)\npathToDressColours &lt;- \"dress_drawings/\"\n## map outfits to the corresponding images\noneRowPerConcert %&gt;%\n    count(DressName) %&gt;%\n    mutate(\n        percentage = n / sum(n) * 100,\n        imagePath = case_when(\n            DressName == \"Pink\" ~paste0(pathToDressColours, \"Pink.png\"),\n            DressName == \"Green\" ~paste0(pathToDressColours, \"Green.png\"),\n            DressName == \"Yellow\" ~paste0(pathToDressColours, \"Yellow.png\"),\n            DressName == \"Blue\" ~paste0(pathToDressColours, \"Blue.png\"),\n            DressName == \"Flamingo pink\" ~ paste0(pathToDressColours,\"Flamingo pink.png\"),\n            DressName == \"Ocean blue\" ~ paste0(pathToDressColours,\"Ocean blue.png\"),\n            DressName == \"Sunset orange\" ~ paste0(pathToDressColours,\"Sunset orange.png\"),\n            DressName == \"Cotton candy\" ~paste0(pathToDressColours, \"Cotton candy.png\"),\n            DressName == \"Blurple\" ~paste0(pathToDressColours, \"Blurple.png\"),\n            DressName == \"Grapefruit\" ~ paste0(pathToDressColours,\"Grapefruit.png\"),\n            DressName == \"Popsicle\" ~ paste0(pathToDressColours,\"Popsicle.png\"),\n            TRUE ~ NA_character_\n        )) -&gt; outfits\n\n## barchart\nggplot(outfits, aes(x = reorder(DressName, -n), y = n, fill = DressName)) +\n    geom_bar(stat = \"identity\", width = 0.8) +  \n    geom_image(\n        aes(image = imagePath, y = n),  \n        size = 0.15,                    \n        by = \"height\"                    \n    ) +\n    geom_text(\n        aes(y = n + 3.8, label = paste0(n, \"\\n(\", round(percentage, 1), \"%)\")),  \n        vjust = 0,  \n        color = \"black\",\n        size = 4\n    ) +\n    scale_fill_manual(values = colorPaletteDresses) +\n    theme_minimal() +\n    labs(title = \"\", x = \"\", y = \"\") +\n    theme(\n        axis.text.x = element_text(angle = 45, hjust = 1, size = 14),\n        axis.text.y = element_text(size = 14),\n        plot.title = element_text(hjust = 0.5, size = 16),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank(),\n        legend.position = \"none\"\n    ) + ylim(0, 35)",
    "crumbs": [
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>Visualizing the data</span>"
    ]
  },
  {
    "objectID": "outfit_transitions.html",
    "href": "outfit_transitions.html",
    "title": "3¬† Are the surprise song outfits random?",
    "section": "",
    "text": "3.1 A \\(\\chi^2\\)-test for the transition counts\nIn this section we‚Äôre going to look at the order of surprise song outfits. First let‚Äôs just select the data we need.\nNow, let‚Äôs look at the outfit transitions by creating a transition matrix using a simple function transition_matrix, which takes a sequence of categorical events and returns a table of the number of observed transitions between each event (in our case named outfits).\nLooking at the outfit transitions.\nThis is quite a sparse table (we know some outfits didn‚Äôt appear until later legs of the tour). So, let‚Äôs consider the transitions for each of the three main legs.\nLikely, the first standard hypothesis test you think of for count/contingency data is the \\(\\chi^2\\)-test (or the chi-squared test). Essentially, this works by testing for equal transition rates (if the outfit choices were completely random we‚Äôd expect equal numbers of transitions between the outfits); Slightly more formally,\n\\(H_0 = \\text{row outfits independent of column outfits}\\) vs.¬†\\(H_1 = \\text{row outfits not independent of column outfits}\\).\n## first leg\nfirst_leg |&gt; transitions() |&gt; chisq.test()\n\n\n    Pearson's Chi-squared test\n\ndata:  transitions(first_leg)\nX-squared = 10.259, df = 9, p-value = 0.33\n\n## europe leg\nmid_leg |&gt; transitions() |&gt; chisq.test()\n\n\n    Pearson's Chi-squared test\n\ndata:  transitions(mid_leg)\nX-squared = 19.554, df = 4, p-value = 0.0006115\n\n## final leg\nfinal_leg |&gt; transitions() |&gt; chisq.test()\n\n\n    Pearson's Chi-squared test\n\ndata:  transitions(final_leg)\nX-squared = 17.337, df = 16, p-value = 0.3641\nTable¬†3.1: Summary of the chi-squared tests on the transition matricies for each leg of the Eras tour.\n\n\n\n\n\n\nChi-squared statistic\nDegrees of freedom\np-vlaue\n\n\n\n\nFirst Leg\n10.259\n9\n0.330\n\n\nEuropean Leg\n19.554\n4\n0.001\n\n\nFinal Leg\n17.337\n16\n0.364\nTherefore, if our \\(\\chi^2\\) assumptions were met we might infer that there‚Äôs some evidence against the outfits for the European leg being random.\nChi-squared distribution under the NULL hypothesis for each leg along with the observed chi-squared statistic in purple.",
    "crumbs": [
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>Are the surprise song outfits random?</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "1¬† The data!",
    "section": "",
    "text": "1.1 The Lore dataset\nThe album_info_metadata.xlsx file includes the fan lore: sentiment, message, keywords, muse, color meaning, notes, secret messages, color mentions and their meanings (between positive or negative). The sentiments were chosen from a list of feelings compiled by the Hoffman Institute Foundation (May/2015 review). Soon it was realized that a single sentiment was not enough to completely differentiate between songs and the message and keywords were also created to add more information to single out a song. For example, while Tim McGraw and Back to December both have the overall nostalgic feeling, the first carries a falling in love message, while the latter is about longing. Likewise, Tim McGraw keywords are romantic, first love, country music, while Back to December keywords are breakup, regretful, heartbreak.\nallSongsMetadata &lt;- readxl::read_excel(\"raw_data/album_info_metadata.xlsx\")[,1:29]\nallSongsMetadata \n\n# A tibble: 240 √ó 29\n   album_name ep    album_release       track_number track_name artist featuring\n   &lt;chr&gt;      &lt;lgl&gt; &lt;dttm&gt;                     &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;    \n 1 Red        FALSE 2021-11-12 00:00:00            6 \"22\"       Taylo‚Ä¶ &lt;NA&gt;     \n 2 1989       FALSE 2023-10-27 00:00:00           17 \"\\\"Slut!\\‚Ä¶ Taylo‚Ä¶ &lt;NA&gt;     \n 3 reputation FALSE 2017-11-10 00:00:00            1 \"...Ready‚Ä¶ Taylo‚Ä¶ &lt;NA&gt;     \n 4 Taylor Sw‚Ä¶ FALSE 2006-10-24 00:00:00           14 \"A Perfec‚Ä¶ Taylo‚Ä¶ &lt;NA&gt;     \n 5 Taylor Sw‚Ä¶ FALSE 2006-10-24 00:00:00            4 \"A Place ‚Ä¶ Taylo‚Ä¶ &lt;NA&gt;     \n 6 Lover      FALSE 2019-08-23 00:00:00           15 \"Afterglo‚Ä¶ Taylo‚Ä¶ &lt;NA&gt;     \n 7 Red        FALSE 2021-11-12 00:00:00            5 \"All Too ‚Ä¶ Taylo‚Ä¶ &lt;NA&gt;     \n 8 Red        FALSE 2021-11-12 00:00:00           30 \"All Too ‚Ä¶ Taylo‚Ä¶ &lt;NA&gt;     \n 9 1989       FALSE 2023-10-27 00:00:00            5 \"All You ‚Ä¶ Taylo‚Ä¶ &lt;NA&gt;     \n10 Midnights  FALSE 2022-10-21 00:00:00            3 \"Anti-Her‚Ä¶ Taylo‚Ä¶ &lt;NA&gt;     \n# ‚Ñπ 230 more rows\n# ‚Ñπ 22 more variables: bonus_track &lt;lgl&gt;, promotional_release &lt;dttm&gt;,\n#   single_release &lt;dttm&gt;, track_release &lt;dttm&gt;, danceability &lt;dbl&gt;,\n#   energy &lt;dbl&gt;, key &lt;dbl&gt;, loudness &lt;dbl&gt;, mode &lt;dbl&gt;, speechiness &lt;dbl&gt;,\n#   acousticness &lt;dbl&gt;, instrumentalness &lt;dbl&gt;, liveness &lt;dbl&gt;, valence &lt;dbl&gt;,\n#   tempo &lt;dbl&gt;, time_signature &lt;dbl&gt;, duration_ms &lt;dbl&gt;, explicit &lt;lgl&gt;,\n#   key_name &lt;chr&gt;, mode_name &lt;chr&gt;, key_mode &lt;chr&gt;, lyrics &lt;chr&gt;",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>The data!</span>"
    ]
  },
  {
    "objectID": "colour_sentiments.html",
    "href": "colour_sentiments.html",
    "title": "4¬† Colour Sentiments",
    "section": "",
    "text": "4.1 \\(\\chi^2\\) test for equal proportions\ncolorSentimentScores$colourGroup &lt;- colorGroups[colorSentimentScores$colour]\ncols.df &lt;- as.data.frame.matrix(table(colorSentimentScores$colourGroup, colorSentimentScores$meaning))\ncols.df\n\n                negative neutral positive\nblack and white        2       2        0\nblacks                 3       7        3\nblues                 18       7       10\ncolorful               1       3       11\ngreens                 0       3        8\npurples                1       1        4\nreds                  15      11       13\nwhites                13      12        5\nyellows                1       9       17\n\n## change col and row names for aesthetic reasons\ncolnames(cols.df) &lt;- str_to_title(colnames(cols.df))\nrownames(cols.df) &lt;- str_to_title(rownames(cols.df))\nrow.props &lt;- prop.table(as.matrix(cols.df), margin = 1)\ncorrplot(row.props, is.corr = FALSE, cl.pos = FALSE)\nThe plot above is not a traditional correlation plot, rather each entry is the row-wise proportion of colour mentions across each sentiment. The shade and size of each circle represent the magnitude of each entry, where darker and larger circles correspond to larger row-wise proportions. Evident from this plot is that for Yellows, Purples, Greens and Colorful we see a higher proportion of mentions associated with Positive sentiment.\nBelow we carry out a (Pearson‚Äôs) chi-squared test where the null hypothesis is that the joint distribution of the cell counts is the product of the row and column marginals:\n\\(H0\\): colours and sentiments are independent vs \\(H1\\): colours and sentiments are dependent,\n## chi-squared test\nchi &lt;- chisq.test(cols.df)\nchi ## strong evidence against NULL\n\n\n    Pearson's Chi-squared test\n\ndata:  cols.df\nX-squared = 47.661, df = 16, p-value = 5.369e-05\n\ncorrplot(chi$residuals, is.corr = FALSE, cl.pos = FALSE)\nAgain, the plot above is not a traditional correlation plot, each entry is the \\(\\chi^2\\) residual (i.e., a measure of deviation from the expected). Red hues indicate fewer than expected counts, and blue hues indicate higher counts than were expected. The sizes and shade of each circle reflect the magnitude of the deviation. Looking at the Yellow row we see that we observe far fewer mentions with negative sentiment and more mentions with positive sentiment, than we might expect under equal counts. Referring back to the table of counts this is clear to see.",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Colour Sentiments</span>"
    ]
  },
  {
    "objectID": "colour_sentiments.html#footnotes",
    "href": "colour_sentiments.html#footnotes",
    "title": "4¬† Colour Sentiments",
    "section": "",
    "text": "important to note that these are abstract constructs!‚Ü©Ô∏é",
    "crumbs": [
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Colour Sentiments</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "‚ÄúBillboard Hot 100‚Ñ¢.‚Äù n.d. https://www.billboard.com/charts/hot-100/.\n\n\nBortoli, Mario De, and Jes√∫s Maroto. 2001. ‚ÄúColours Across\nCultures: Translating Colours in Interactive Marketing\nCommunications.‚Äù In European Languages and the Implementation\nof Communication and Information Technologies (Elicit) Conference.\n\n\nKaufman, Gil. 2025. ‚ÄúOrange You Glad Taylor Swift Is Back?‚Äù\nBillboard, August. https://www.billboard.com/music/pop/taylor-orange-life-showgirl-album-memes-elmo-target-brands-1236042681/.\n\n\nOlson, Samantha. 2022. ‚ÄúAll the Easter Eggs in Taylor Swift‚Äôs\nBejeweled Music Video.‚Äù Seventeen, October. https://www.seventeen.com/celebrity/music/a41766334/taylor-swift-bejeweled-music-video-easter-eggs/.\n\n\nRinker, Tyler W. 2021. ‚ÄúSentimentr: Calculate Text\nPolarity.‚Äù\n\n\nRowley, Glenn. 2023. ‚ÄúTaylor Swift‚Äôs the Eras Tour Easter Eggs:\nHere‚Äôs What Fans Have Spotted.‚Äù Billboard, May. https://www.billboard.com/lists/taylor-swift-eras-tour-easter-eggs/the-red-taylors-version-t-shirt/.\n\n\nSavage, Mark. 2024. ‚ÄúTaylor Swift: As the Eras Tour Bows Out, What\nWill She Do Next?‚Äù BBC, December. https://www.bbc.com/news/articles/ckg1r0v838vo.\n\n\nThompson, W Jake. 2025. ‚ÄúTaylor: Lyrics and Song Data for Taylor\nSwift‚Äôs Discography.‚Äù",
    "crumbs": [
      "References"
    ]
  }
]